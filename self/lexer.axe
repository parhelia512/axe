// Author: Navid Momtahen (C) 2025
// License: GPL-3.0

use std.string;
use std.lists;

enum TokenType {
    IDENTIFIER,
    NUMBER,
    STR,
    CHAR,
    INTERPOLATED_STR,
    COMMENT,
    WHITESPACE,
    NEWLINE,
    LPAREN,
    RPAREN,
    LBRACE,
    RBRACE,
    LBRACKET,
    RBRACKET,
    COMMA,
    DOT,
    COLON,
    SEMICOLON,
    PLUS,
    MINUS,
    STAR,
    SLASH,
    OPERATOR,
    INCREMENT,
    DECREMENT,
    AND,
    OR,
    NOT,
    FN,
    LET,
    MUT,
    IF,
    ELSE,
    ELIF,
    WHILE,
    FOR,
    IN,
    RETURN,
    BREAK,
    CONTINUE,
    MODEL,
    ENUM,
    USE,
    MATCH,
    CASE,
    TEST,
    ASSERT,
    REF,
    MACRO,
    RAW,
    PLATFORM,
    PARALLEL,
    LOCAL,
    SINGLE,
    WINDOWS,
    POSIX,
    TO,
    REDUCE,
    OPAQUE,
    EXTERN,
    UNSAFE,
    STAR_DOT,
    PUB,
    PRINT,
    DEF,
    VAL,
    MAIN,
    MOD,
    DEFAULT,
    LOOP,
    NEW,
    OVERLOAD,
    EXTERNAL,
    SWITCH,
    XOR
}

pub model Token {
    pub token_type: i32;
    pub value: string;
    pub line: i32;
    pub column: i32;
}

def create_token(token_type: i32, value: ref char): Token {
    mut t: Token;
    t.token_type = token_type;
    t.value = str(value);
    return t;
}

def is_hex_digit(ch: char): bool {
    return (ch >= '0' and ch <= '9') or (ch >= 'a' and ch <= 'f') or (ch >= 'A' and ch <= 'F');
}

def is_whitespace(ch: char): bool {
    return ch == ' ' or ch == '\t' or ch == '\r';
}

def is_ident_char(ch: char): bool {
    if is_alphanum(ch) != 0 {
        return true;
    }
    if ch == '_' {
        return true;
    }
    return false;
}

def check_boundary(source: string, pos: i32, source_len: i32): bool {
    if pos >= source_len {
        return true;
    }
    mut ch: char = source.data[pos];
    return !is_ident_char(ch);
}

def str_equals(s1: string, s2: ref char, start: i32, len: i32, source_len: i32): bool {
    if start + len > source_len {
        return false;
    }
    mut i: i32 = 0;
    loop {
        if i >= len {
            break;
        }
        if get_char(s1, start + i) != s2[i] {
            return false;
        }
        i++;
    }
    return true;
}

pub def lex(source: string): list(Token) {
    mut tokens: list(Token);
    mut pos: i32 = 0;
    mut source_len: i32 = source.len;
    
    loop {
        if pos >= source_len {
            break;
        }
        mut ch: char = get_char(source, pos);
        
        if ch == '*' {
            if pos + 1 < source_len and get_char(source, pos + 1) == '.' {
                append(tokens, create_token(TokenType.STAR_DOT, "*."));
                pos = pos + 2;
            } else {
                append(tokens, create_token(TokenType.STAR, "*"));
                pos = pos + 1;
            }
        } elif ch == ' ' or ch == '\t' or ch == '\r' {
            append(tokens, create_token(TokenType.WHITESPACE, substring_scse(source, pos, pos + 1)));
            pos = pos + 1;
        } elif ch == '\n' {
            append(tokens, create_token(TokenType.NEWLINE, "\n"));
            pos = pos + 1;
        } elif ch == '{' {
            append(tokens, create_token(TokenType.LBRACE, "{"));
            pos = pos + 1;
        } elif ch == '}' {
            append(tokens, create_token(TokenType.RBRACE, "}"));
            pos = pos + 1;
        } elif ch == ';' {
            append(tokens, create_token(TokenType.SEMICOLON, ";"));
            pos = pos + 1;
        } elif ch == ':' {
            append(tokens, create_token(TokenType.COLON, ":"));
            pos = pos + 1;
        } elif ch == '!' {
            if pos + 1 < source_len and get_char(source, pos + 1) == '=' {
                append(tokens, create_token(TokenType.OPERATOR, "!="));
                pos = pos + 2;
            } else {
                append(tokens, create_token(TokenType.OPERATOR, "!"));
                pos = pos + 1;
            }
        } elif ch == '=' {
            if pos + 1 < source_len and get_char(source, pos + 1) == '=' {
                append(tokens, create_token(TokenType.OPERATOR, "=="));
                pos = pos + 2;
            } elif pos + 1 < source_len and get_char(source, pos + 1) == '>' {
                append(tokens, create_token(TokenType.OPERATOR, "=>"));
                pos = pos + 2;
            } else {
                append(tokens, create_token(TokenType.OPERATOR, "="));
                pos = pos + 1;
            }
        } elif ch == '-' {
            if pos + 1 < source_len and get_char(source, pos + 1) == '-' {
                append(tokens, create_token(TokenType.DECREMENT, "--"));
                pos = pos + 2;
            } else {
                append(tokens, create_token(TokenType.MINUS, "-"));
                pos = pos + 1;
            }
        } elif ch == '+' {
            if pos + 1 < source_len and get_char(source, pos + 1) == '+' {
                append(tokens, create_token(TokenType.INCREMENT, "++"));
                pos = pos + 2;
            } else {
                append(tokens, create_token(TokenType.PLUS, "+"));
                pos = pos + 1;
            }
        } elif ch == '>' {
            if pos + 1 < source_len and get_char(source, pos + 1) == '=' {
                append(tokens, create_token(TokenType.OPERATOR, ">="));
                pos = pos + 2;
            } elif pos + 1 < source_len and get_char(source, pos + 1) == '>' {
                append(tokens, create_token(TokenType.OPERATOR, ">>"));
                pos = pos + 2;
            } else {
                append(tokens, create_token(TokenType.OPERATOR, ">"));
                pos = pos + 1;
            }
        } elif ch == '<' {
            if pos + 1 < source_len and get_char(source, pos + 1) == '=' {
                append(tokens, create_token(TokenType.OPERATOR, "<="));
                pos = pos + 2;
            } elif pos + 1 < source_len and get_char(source, pos + 1) == '<' {
                append(tokens, create_token(TokenType.OPERATOR, "<<"));
                pos = pos + 2;
            } else {
                append(tokens, create_token(TokenType.OPERATOR, "<"));
                pos = pos + 1;
            }
        } elif ch == '/' {
            if pos + 1 < source_len and get_char(source, pos + 1) == '/' {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or get_char(source, pos) == '\n' {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.COMMENT, substring_scse(source, start, pos)));
            } else {
                append(tokens, create_token(TokenType.SLASH, "/"));
                pos = pos + 1;
            }
        } elif ch == '&' {
            append(tokens, create_token(TokenType.OPERATOR, "&"));
            pos = pos + 1;
        } elif ch == '|' {
            append(tokens, create_token(TokenType.OPERATOR, "|"));
            pos = pos + 1;
        } elif ch == '^' {
            append(tokens, create_token(TokenType.OPERATOR, "^"));
            pos = pos + 1;
        } elif ch == '~' {
            append(tokens, create_token(TokenType.OPERATOR, "~"));
            pos = pos + 1;
        } elif ch == '%' {
            append(tokens, create_token(TokenType.OPERATOR, "%"));
            pos = pos + 1;
        } elif ch == '$' {
            if pos + 1 < source_len and get_char(source, pos + 1) == '"' {
                pos = pos + 2;
                mut str_start: i32 = pos;
                mut ending: i32 = pos;
                loop {
                    if ending >= source_len {
                        break;
                    }
                    if get_char(source, ending) == '"' and (ending == 0 or get_char(source, ending - 1) != '\\') {
                        break;
                    } elif get_char(source, ending) == '\\' and ending + 1 < source_len {
                        ending = ending + 2;
                    } else {
                        ending = ending + 1;
                    }
                }
                mut raw_inter: string = str(substring_scse(source, str_start, ending));
                mut wrapped: string = str("__INTERPOLATED__");
                wrapped = concat(wrapped, raw_inter);
                wrapped = concat(wrapped, str("__INTERPOLATED__"));
                append(tokens, create_token(TokenType.INTERPOLATED_STR, wrapped.data));
                pos = ending + 1;
            }
        } elif ch == '"' {
            mut ending: i32 = pos + 1;
            loop {
                if ending >= source_len {
                    break;
                }
                if get_char(source, ending) == '"' {
                    break;
                } elif get_char(source, ending) == '\\' and ending + 1 < source_len {
                    ending = ending + 2;
                } else {
                    ending = ending + 1;
                }
            }
            append(tokens, create_token(TokenType.STR, substring_scse(source, pos + 1, ending)));
            pos = ending + 1;
        } elif cast[i32](ch) == 96 {
            // Backtick multi-line string literal
            mut bt_end: i32 = pos + 1;
            loop {
                if bt_end >= source_len {
                    break;
                }
                if cast[i32](get_char(source, bt_end)) == 96 {
                    break;
                }
                bt_end = bt_end + 1;
            }
            val raw_content: string = str(substring_scse(source, pos + 1, bt_end));
            mut sb: StringBuilder = StringBuilder.init(cast[usize]((bt_end - pos) * 2));
            mut ri: i32 = 0;
            loop {
                if ri >= str_len(raw_content) {
                    break;
                }
                val rc: char = get_char(raw_content, ri);
                if rc == '\n' {
                    StringBuilder.append_c(addr(sb), "\\n");
                } elif rc == '\r' {
                    StringBuilder.append_c(addr(sb), "\\r");
                } elif rc == '\t' {
                    StringBuilder.append_c(addr(sb), "\\t");
                } elif rc == '"' {
                    StringBuilder.append_c(addr(sb), "\\\"");
                } elif rc == '\\' {
                    StringBuilder.append_c(addr(sb), "\\\\");
                } else {
                    StringBuilder.append_char(addr(sb), rc);
                }
                ri = ri + 1;
            }
            val escaped_content: string = StringBuilder.to_string(addr(sb));
            StringBuilder.destroy(addr(sb));
            append(tokens, create_token(TokenType.STR, escaped_content.data));
            pos = bt_end + 1;
        } elif cast[i32](ch) == 39 {
            mut cend: i32 = pos + 1;
            loop {
                if cend >= source_len or cast[i32](get_char(source, cend)) == 39 {
                    break;
                }
                if cast[i32](get_char(source, cend)) == 92 and cend + 1 < source_len {
                    cend = cend + 2;
                } else {
                    cend = cend + 1;
                }
            }
            append(tokens, create_token(TokenType.CHAR, substring_scse(source, pos + 1, cend)));
            pos = cend + 1;
        } elif ch == '(' {
            append(tokens, create_token(TokenType.LPAREN, "("));
            pos = pos + 1;
        } elif ch == ')' {
            append(tokens, create_token(TokenType.RPAREN, ")"));
            pos = pos + 1;
        } elif ch == ',' {
            append(tokens, create_token(TokenType.COMMA, ","));
            pos = pos + 1;
        } elif ch == '[' {
            append(tokens, create_token(TokenType.LBRACKET, "["));
            pos = pos + 1;
        } elif ch == ']' {
            append(tokens, create_token(TokenType.RBRACKET, "]"));
            pos = pos + 1;
        } elif ch == '.' {
            append(tokens, create_token(TokenType.DOT, "."));
            pos = pos + 1;
        } elif ch == 'a' {
            if str_equals(source, "assert", pos, 6, source_len) and check_boundary(source, pos + 6, source_len) {
                append(tokens, create_token(TokenType.ASSERT, "assert"));
                pos = pos + 6;
            } elif str_equals(source, "and", pos, 3, source_len) and check_boundary(source, pos + 3, source_len) {
                append(tokens, create_token(TokenType.AND, "and"));
                pos = pos + 3;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'b' {
            if str_equals(source, "break", pos, 5, source_len) and check_boundary(source, pos + 5, source_len) {
                append(tokens, create_token(TokenType.BREAK, "break"));
                pos = pos + 5;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'c' {
            if str_equals(source, "continue", pos, 8, source_len) and check_boundary(source, pos + 8, source_len) {
                append(tokens, create_token(TokenType.CONTINUE, "continue"));
                pos = pos + 8;
            } elif str_equals(source, "case", pos, 4, source_len) and check_boundary(source, pos + 4, source_len) {
                append(tokens, create_token(TokenType.CASE, "case"));
                pos = pos + 4;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'd' {
            if str_equals(source, "default", pos, 7, source_len) and check_boundary(source, pos + 7, source_len) {
                append(tokens, create_token(TokenType.DEFAULT, "default"));
                pos = pos + 7;
            } elif str_equals(source, "def", pos, 3, source_len) and check_boundary(source, pos + 3, source_len) {
                mut lookAhead: i32 = pos + 3;
                loop {
                    if lookAhead >= source_len {
                        break;
                    }
                    mut ch_look: char = get_char(source, lookAhead);
                    if ch_look != ' ' and ch_look != '\t' {
                        break;
                    }
                    lookAhead = lookAhead + 1;
                }

                if str_equals(source, "main", lookAhead, 4, source_len) and check_boundary(source, lookAhead + 4, source_len) {
                    lookAhead = lookAhead + 4;
                    loop {
                        if lookAhead >= source_len {
                            break;
                        }
                        mut ch_look: char = get_char(source, lookAhead);
                        if ch_look != ' ' and ch_look != '\t' {
                            break;
                        }
                        lookAhead = lookAhead + 1;
                    }

                    if lookAhead + 1 < source_len and get_char(source, lookAhead) == '(' and get_char(source, lookAhead + 1) == ')' {
                        append(tokens, create_token(TokenType.MAIN, "main"));
                        pos = lookAhead + 2;
                    } elif lookAhead < source_len and get_char(source, lookAhead) == '{' {
                        append(tokens, create_token(TokenType.MAIN, "main"));
                        pos = lookAhead;
                    } else {
                        append(tokens, create_token(TokenType.DEF, "def"));
                        pos = pos + 3;
                    }
                } else {
                    append(tokens, create_token(TokenType.DEF, "def"));
                    pos = pos + 3;
                }
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'e' {
            if str_equals(source, "external", pos, 8, source_len) and check_boundary(source, pos + 8, source_len) {
                append(tokens, create_token(TokenType.EXTERNAL, "external"));
                pos = pos + 8;
            } elif str_equals(source, "extern", pos, 6, source_len) and check_boundary(source, pos + 6, source_len) {
                append(tokens, create_token(TokenType.EXTERN, "extern"));
                pos = pos + 6;
            } elif str_equals(source, "enum", pos, 4, source_len) and check_boundary(source, pos + 4, source_len) {
                append(tokens, create_token(TokenType.ENUM, "enum"));
                pos = pos + 4;
            } elif str_equals(source, "elif", pos, 4, source_len) and check_boundary(source, pos + 4, source_len) {
                append(tokens, create_token(TokenType.ELIF, "elif"));
                pos = pos + 4;
            } elif str_equals(source, "else", pos, 4, source_len) and check_boundary(source, pos + 4, source_len) {
                append(tokens, create_token(TokenType.ELSE, "else"));
                pos = pos + 4;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'f' {
            if str_equals(source, "for", pos, 3, source_len) and check_boundary(source, pos + 3, source_len) {
                append(tokens, create_token(TokenType.FOR, "for"));
                pos = pos + 3;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'i' {
            if str_equals(source, "in", pos, 2, source_len) and check_boundary(source, pos + 2, source_len) {
                append(tokens, create_token(TokenType.IN, "in"));
                pos = pos + 2;
            } elif str_equals(source, "if", pos, 2, source_len) and check_boundary(source, pos + 2, source_len) {
                append(tokens, create_token(TokenType.IF, "if"));
                pos = pos + 2;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'l' {
            if str_equals(source, "loop", pos, 4, source_len) and check_boundary(source, pos + 4, source_len) {
                append(tokens, create_token(TokenType.LOOP, "loop"));
                pos = pos + 4;
            } elif str_equals(source, "local", pos, 5, source_len) and check_boundary(source, pos + 5, source_len) {
                append(tokens, create_token(TokenType.LOCAL, "local"));
                pos = pos + 5;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'm' {
            if str_equals(source, "macro", pos, 5, source_len) and check_boundary(source, pos + 5, source_len) {
                append(tokens, create_token(TokenType.MACRO, "macro"));
                pos = pos + 5;
            } elif str_equals(source, "model", pos, 5, source_len) and check_boundary(source, pos + 5, source_len) {
                append(tokens, create_token(TokenType.MODEL, "model"));
                pos = pos + 5;
            } elif str_equals(source, "main", pos, 4, source_len) and check_boundary(source, pos + 4, source_len) {
                append(tokens, create_token(TokenType.MAIN, "main"));
                pos = pos + 4;
            } elif str_equals(source, "mut", pos, 3, source_len) and check_boundary(source, pos + 3, source_len) {
                append(tokens, create_token(TokenType.MUT, "mut"));
                pos = pos + 3;
            } elif str_equals(source, "mod", pos, 3, source_len) and check_boundary(source, pos + 3, source_len) {
                append(tokens, create_token(TokenType.MOD, "mod"));
                pos = pos + 3;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'n' {
            if str_equals(source, "new", pos, 3, source_len) and check_boundary(source, pos + 3, source_len) {
                append(tokens, create_token(TokenType.NEW, "new"));
                pos = pos + 3;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'o' {
            if str_equals(source, "overload", pos, 8, source_len) and check_boundary(source, pos + 8, source_len) {
                append(tokens, create_token(TokenType.OVERLOAD, "overload"));
                pos = pos + 8;
            } elif str_equals(source, "opaque", pos, 6, source_len) and check_boundary(source, pos + 6, source_len) {
                append(tokens, create_token(TokenType.OPAQUE, "opaque"));
                pos = pos + 6;
            } elif str_equals(source, "or", pos, 2, source_len) and check_boundary(source, pos + 2, source_len) {
                append(tokens, create_token(TokenType.OR, "or"));
                pos = pos + 2;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'p' {
            if str_equals(source, "platform", pos, 8, source_len) and check_boundary(source, pos + 8, source_len) {
                append(tokens, create_token(TokenType.PLATFORM, "platform"));
                pos = pos + 8;
            } elif str_equals(source, "parallel", pos, 8, source_len) and check_boundary(source, pos + 8, source_len) {
                append(tokens, create_token(TokenType.PARALLEL, "parallel"));
                pos = pos + 8;
            } elif str_equals(source, "posix", pos, 5, source_len) and check_boundary(source, pos + 5, source_len) {
                append(tokens, create_token(TokenType.POSIX, "posix"));
                pos = pos + 5;
            } elif str_equals(source, "pub", pos, 3, source_len) and check_boundary(source, pos + 3, source_len) {
                append(tokens, create_token(TokenType.PUB, "pub"));
                pos = pos + 3;
            } elif str_equals(source, "put", pos, 3, source_len) and check_boundary(source, pos + 3, source_len) {
                append(tokens, create_token(TokenType.PRINT, "put"));
                pos = pos + 3;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'r' {
            if str_equals(source, "return", pos, 6, source_len) and check_boundary(source, pos + 6, source_len) {
                append(tokens, create_token(TokenType.RETURN, "return"));
                pos = pos + 6;
            } elif str_equals(source, "reduce", pos, 6, source_len) and check_boundary(source, pos + 6, source_len) {
                append(tokens, create_token(TokenType.REDUCE, "reduce"));
                pos = pos + 6;
            } elif str_equals(source, "ref", pos, 3, source_len) and check_boundary(source, pos + 3, source_len) {
                append(tokens, create_token(TokenType.REF, "ref"));
                pos = pos + 3;
            } elif str_equals(source, "raw", pos, 3, source_len) and check_boundary(source, pos + 3, source_len) {
                append(tokens, create_token(TokenType.RAW, "raw"));
                pos = pos + 3;
                loop {
                    if pos >= source_len or (!is_whitespace(get_char(source, pos)) and get_char(source, pos) != '\n') {
                        break;
                    }
                    if get_char(source, pos) == '\n' {
                        append(tokens, create_token(TokenType.NEWLINE, "\n"));
                    } elif get_char(source, pos) == ' ' or get_char(source, pos) == '\t' {
                        append(tokens, create_token(TokenType.WHITESPACE, substring_scse(source, pos, pos + 1)));
                    }
                    pos = pos + 1;
                }
                if pos < source_len and get_char(source, pos) == '{' {
                    append(tokens, create_token(TokenType.LBRACE, "{"));
                    pos = pos + 1;
                    mut brace_depth: i32 = 1;
                    mut content_start: i32 = pos;
                    loop {
                        if pos >= source_len or brace_depth <= 0 {
                            break;
                        }
                        if get_char(source, pos) == '{' {
                            brace_depth = brace_depth + 1;
                        } elif get_char(source, pos) == '}' {
                            brace_depth = brace_depth - 1;
                            if brace_depth == 0 {
                                break;
                            }
                        }
                        pos = pos + 1;
                    }
                    if pos > content_start {
                        append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, content_start, pos)));
                    }
                    if pos < source_len and get_char(source, pos) == '}' {
                        append(tokens, create_token(TokenType.RBRACE, "}"));
                        pos = pos + 1;
                    }
                }
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 's' {
            if str_equals(source, "switch", pos, 6, source_len) and check_boundary(source, pos + 6, source_len) {
                append(tokens, create_token(TokenType.SWITCH, "switch"));
                pos = pos + 6;
            } elif str_equals(source, "single", pos, 6, source_len) and check_boundary(source, pos + 6, source_len) {
                append(tokens, create_token(TokenType.SINGLE, "single"));
                pos = pos + 6;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 't' {
            if str_equals(source, "test", pos, 4, source_len) and check_boundary(source, pos + 4, source_len) {
                append(tokens, create_token(TokenType.TEST, "test"));
                pos = pos + 4;
            } elif str_equals(source, "to", pos, 2, source_len) and check_boundary(source, pos + 2, source_len) {
                append(tokens, create_token(TokenType.TO, "to"));
                pos = pos + 2;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'u' {
            if str_equals(source, "unsafe", pos, 6, source_len) and check_boundary(source, pos + 6, source_len) {
                append(tokens, create_token(TokenType.UNSAFE, "unsafe"));
                pos = pos + 6;
            } elif str_equals(source, "use", pos, 3, source_len) and check_boundary(source, pos + 3, source_len) {
                append(tokens, create_token(TokenType.USE, "use"));
                pos = pos + 3;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'v' {
            
            // Match 'val' keyword only at word boundaries so we don't split identifiers
            // like 'value' into 'val' + 'ue'. We require both:
            //
            //   - preceding char is not an identifier char (or we're at start)
            //   - following char is not an identifier char (via check_boundary)

            mut at_word_start: bool = false;
            if pos == 0 {
                at_word_start = true;
            } else {
                val prev_ch: char = get_char(source, pos - 1);
                if !is_ident_char(prev_ch) {
                    at_word_start = true;
                }
            }

            if at_word_start and str_equals(source, "val", pos, 3, source_len) and check_boundary(source, pos + 3, source_len) {
                append(tokens, create_token(TokenType.VAL, "val"));
                pos = pos + 3;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'w' {
            if str_equals(source, "windows", pos, 7, source_len) and check_boundary(source, pos + 7, source_len) {
                append(tokens, create_token(TokenType.WINDOWS, "windows"));
                pos = pos + 7;
            } elif str_equals(source, "while", pos, 5, source_len) and check_boundary(source, pos + 5, source_len) {
                append(tokens, create_token(TokenType.WHILE, "while"));
                pos = pos + 5;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == 'x' {
            if str_equals(source, "xor", pos, 3, source_len) and check_boundary(source, pos + 3, source_len) {
                append(tokens, create_token(TokenType.XOR, "xor"));
                pos = pos + 3;
            } else {
                mut start: i32 = pos;
                loop {
                    if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                        break;
                    }
                    pos = pos + 1;
                }
                append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
            }
        } elif ch == '0' and pos + 1 < source_len and (get_char(source, pos + 1) == 'x' or get_char(source, pos + 1) == 'X') {
            mut start: i32 = pos;
            pos = pos + 2;
            loop {
                if pos >= source_len or !is_hex_digit(get_char(source, pos)) {
                    break;
                }
                pos = pos + 1;
            }
            append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
        } elif is_ident_char(ch) {
            mut start: i32 = pos;
            loop {
                if pos >= source_len or !is_ident_char(get_char(source, pos)) {
                    break;
                }
                pos = pos + 1;
            }
            append(tokens, create_token(TokenType.IDENTIFIER, substring_scse(source, start, pos)));
        } else {
            pos = pos + 1;
        }
    }
    
    return tokens;
}

test {
    mut test_src: string = string.create("mut x = 10;");
    mut test1: list(Token) = lex(test_src);
    for t in test1 {
        println(t.value);
    }
}
