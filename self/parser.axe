// Author: Navid Momtahen (C) 2025
// License: GPL-3.0
// 
// Handles the parsing process - converts tokens into an AST

use lexer (
    Token, 
    TokenType, lex
);

use structs (
    ASTNode,
    ParserContext,
    Scope
);

use std.string;
use std.io;
use std.maps;
use std.arena;
use std.errors;

mut g_type_aliases: StringStringMap;
mut g_imported_modules: StringBoolMap;
mut g_list_of_types: StringStringMap;

/// Initialize the state-related globals
pub def initialize_all() {
    mut arena: Arena = Arena.create(1024 * 1024);
    g_type_aliases = deref(StringStringMap.create(ref_of(arena), 128));
    g_imported_modules = deref(StringBoolMap.create(ref_of(arena), 128));
    g_list_of_types = deref(StringStringMap.create(ref_of(arena), 128));
}

/// Add a child AST node to a parent AST node
def add_child_to_ast(ast: ref ASTNode, child: ASTNode) {
    if ast.children == nil {
        unsafe {
            mut new_list: list(ASTNode);
            val list_size: usize = C.sizeof(list(ASTNode));
            val heap_list: ref list(ASTNode) = cast[ref list(ASTNode)](C.malloc(list_size));
            if heap_list != nil {
                C.memcpy(heap_list, addr_of(new_list), list_size);
                ast.children = heap_list;
            }
        }
    }
    
    if ast.children != nil {
        unsafe {
            mut temp_list: list(ASTNode);
            val list_size: usize = C.sizeof(list(ASTNode));
            C.memcpy(addr_of(temp_list), ast.children, list_size);
            append(temp_list, child);          
            C.memcpy(ast.children, addr_of(temp_list), list_size);
        }
    }
}

/// Parse the tokens into an AST
pub def parse(tokens: ref list(Token), is_axec: bool, check_entry_point: bool, current_module: string): ASTNode {
    mut ctx: ParserContext;
    ctx.tokens = tokens;
    ctx.pos = 0;
    ctx.is_axec = is_axec;
    ctx.check_entry_point = check_entry_point;
    ctx.current_module = current_module;
    
    println "=== DEBUG TOKENS ===";
    mut i: i32 = 0;
    loop {
        if i >= len(ctx.tokens) {
            break;
        }
        val t: Token = ctx.tokens.data[i];
        println i;
        println t.token_type;
        println t.value;
        i = i + 1;
    }
    println "=== END TOKENS ===";


    mut ast: ASTNode;
    ast.node_type = str("Program");
    
    StringStringMap.clear(addr_of(g_type_aliases));
    StringBoolMap.clear(addr_of(g_imported_modules));
    StringStringMap.clear(addr_of(g_list_of_types));
    
    if str_len(current_module) > 0 {
        // g_imported_modules[current_module] = true
        println "Auto-imported current module: ";
        println current_module;
    }
    
    loop {
        if ctx.pos >= len(ctx.tokens) {
            break;
        }
        skip_whitespace(addr_of(ctx));        
        if ctx.pos >= len(ctx.tokens) {
            break;
        }
        parse_top_level(addr_of(ctx), addr_of(ast));
    }
    
    return ast;
}

/// Parse a top-level construct (use, def, model, enum, val, mut val, etc.)
def parse_top_level(ctx: ref ParserContext, ast: ref ASTNode) {
    if ctx.pos >= len(ctx.tokens) {
        return;
    }
    
    val token_type = ctx.tokens.data[ctx.pos].token_type;
    
    if token_type == TokenType.USE {
        mut node: ASTNode = parse_statement_helper(ctx, addr_of(ctx.current_scope));
        if str_len(node.node_type) > 0 {
            add_child_to_ast(ast, node);
        }
        return;
    }
    
    if token_type == TokenType.MAIN {
        ctx.pos++;
        skip_whitespace(ctx);
        
        if ctx.pos >= len(ctx.tokens) or ctx.tokens.data[ctx.pos].token_type != TokenType.LBRACE {
            enforce_raw(false, "Expected '{' after 'def main()'" );
            return;
        }
        ctx.pos++; // Skip '{'
        
        mut main_node: ASTNode;
        main_node.node_type = str("Function");
        main_node.data.function.name = str("main");
        main_node.data.function.return_type = str("");
        main_node.data.function.is_public = false;
        
        unsafe {
            mut empty_params: list(string);
            val params_size: usize = C.sizeof(list(string));
            val heap_params: ref list(string) = cast[ref list(string)](C.malloc(params_size));
            if heap_params != nil {
                C.memcpy(heap_params, addr_of(empty_params), params_size);
                main_node.data.function.params = heap_params;
            }
        }
        
        mut children: list(ASTNode);
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            
            skip_whitespace(ctx);
            
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            
            if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                ctx.pos++; // Skip '}'
                break;
            }
            
            mut stmt: ASTNode = parse_statement_helper(ctx, addr_of(ctx.current_scope));
            if str_len(stmt.node_type) > 0 {
                append(children, stmt);
            }
        }
        
        unsafe {
            val list_size: usize = C.sizeof(list(ASTNode));
            val heap_list: ref list(ASTNode) = cast[ref list(ASTNode)](C.malloc(list_size));
            if heap_list != nil {
                C.memcpy(heap_list, addr_of(children), list_size);
                main_node.children = heap_list;
            }
        }
        
        add_child_to_ast(ast, main_node);
        return;
    }
    
    if token_type == TokenType.DEF {
        ctx.pos++; // Skip 'def'
        mut func_node: ASTNode = parse_function(ctx);
        if str_len(func_node.node_type) > 0 {
            add_child_to_ast(ast, func_node);
        }
        return;
    }
    
    if token_type == TokenType.MODEL {
        ctx.pos++;
        skip_whitespace(ctx);

        if ctx.pos >= len(ctx.tokens) or ctx.tokens.data[ctx.pos].token_type != TokenType.IDENTIFIER {
            enforce_raw(false, "ERROR: Expected model name after 'model'");
            return;
        }

        mut model_node: ASTNode;
        model_node.node_type = str("Model");
        val model_name: string = ctx.tokens.data[ctx.pos].value;
        model_node.data.model_node.name = model_name;
        model_node.data.model_node.is_public = false;
        ctx.pos++;

        skip_whitespace(ctx);
        if ctx.pos >= len(ctx.tokens) or ctx.tokens.data[ctx.pos].token_type != TokenType.LBRACE {
            enforce_raw(false, "ERROR: Expected '{' after model name");
            return;
        }
        ctx.pos++; // Skip '{'

        mut field_names: list(string);
        mut field_types: list(string);

        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }

            skip_whitespace(ctx);
            if ctx.pos >= len(ctx.tokens) {
                break;
            }

            if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                ctx.pos++; // Skip '}'
                break;
            }

            if ctx.tokens.data[ctx.pos].token_type == TokenType.PUB {
                ctx.pos++;
                skip_whitespace(ctx);
            }

            if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
                val field_name: string = ctx.tokens.data[ctx.pos].value;
                ctx.pos++;

                skip_whitespace(ctx);

                if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.COLON {
                    ctx.pos++;
                    skip_whitespace(ctx);

                    // Parse base type
                    mut field_type: string = parse_type(ctx);

                    loop {
                        skip_whitespace(ctx);
                        if ctx.pos >= len(ctx.tokens) {
                            break;
                        }

                        if ctx.tokens.data[ctx.pos].token_type == TokenType.DOT {
                            field_type = concat(field_type, str("."));
                            ctx.pos++;

                            skip_whitespace(ctx);

                            if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
                                field_type = concat(field_type, ctx.tokens.data[ctx.pos].value);
                                ctx.pos++;
                            } else {
                                break;
                            }
                        } elif ctx.tokens.data[ctx.pos].token_type == TokenType.SLASH {
                            field_type = concat(field_type, str("/"));
                            ctx.pos++;

                            skip_whitespace(ctx);

                            if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
                                field_type = concat(field_type, ctx.tokens.data[ctx.pos].value);
                                ctx.pos++;
                            } else {
                                break;
                            }
                        } else {
                            break;
                        }
                    }

                    skip_whitespace(ctx);
                    if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.SEMICOLON {
                        ctx.pos++;
                    }

                    append(field_names, field_name);
                    append(field_types, field_type);
                } else {
                    // No type annotation, skip to semicolon
                    loop {
                        if ctx.pos >= len(ctx.tokens) {
                            break;
                        }
                        val t: Token = ctx.tokens.data[ctx.pos];
                        if t.token_type == TokenType.SEMICOLON {
                            ctx.pos++;
                            break;
                        }
                        ctx.pos++;
                    }
                }
            } else {
                ctx.pos++;
            }
        }

        unsafe {
            val list_size: usize = C.sizeof(list(string));
            val heap_names: ref list(string) = cast[ref list(string)](C.malloc(list_size));
            if heap_names != nil {
                C.memcpy(heap_names, addr_of(field_names), list_size);
                model_node.data.model_node.field_names = heap_names;
            }

            val heap_types: ref list(string) = cast[ref list(string)](C.malloc(list_size));
            if heap_types != nil {
                C.memcpy(heap_types, addr_of(field_types), list_size);
                model_node.data.model_node.field_types = heap_types;
            }
        }

        add_child_to_ast(ast, model_node);
        return;
    }
    
    if token_type == TokenType.ENUM {
        ctx.pos++;  // Skip 'enum'
        skip_whitespace(ctx);
        
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
            ctx.pos++;
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    if token_type == TokenType.MUT {
        ctx.pos++;
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.VAL {
            ctx.pos++;  // Skip 'val'
        }
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            if ctx.tokens.data[ctx.pos].token_type == TokenType.SEMICOLON {
                ctx.pos++;
                break;
            }
            ctx.pos++;
        }
        return;
    }
    
    if token_type == TokenType.VAL {
        ctx.pos++;  // Skip 'val'
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            if ctx.tokens.data[ctx.pos].token_type == TokenType.SEMICOLON {
                ctx.pos++;
                break;
            }
            ctx.pos++;
        }
        return;
    }
    
    if token_type == TokenType.TEST {
        ctx.pos++;  // Skip 'test'
        skip_whitespace(ctx);
        
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    if token_type == TokenType.OVERLOAD {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.IDENTIFIER) {
            enforce_raw(false, "ERROR: Expected overload name after 'overload'");
            return;
        }
        val overload_name: Token = consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LPAREN) {
            enforce_raw(false, "ERROR: Expected '(' after overload name");
            return;
        }
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.IDENTIFIER) {
            enforce_raw(false, "ERROR: Expected parameter name in overload");
            return;
        }
        val param_name_token: Token = consume(ctx);
        val param_name: string = param_name_token.value;
        skip_whitespace(ctx);
        
        if expect(ctx, TokenType.COLON) {
            consume(ctx);
            skip_whitespace(ctx);
            if expect(ctx, TokenType.IDENTIFIER) {
                consume(ctx); // Skip type annotation (e.g., 'generic')
                skip_whitespace(ctx);
            }
        }
        
        if !expect(ctx, TokenType.RPAREN) {
            enforce_raw(false, "ERROR: Expected ')' after overload parameter");
            return;
        }
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after overload header");
            return;
        }
        consume(ctx);
        
        // Parse type mappings: type => function;
        mut type_names: list(string);
        mut target_funcs: list(string);
        
        loop {
            skip_whitespace(ctx);
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            if expect(ctx, TokenType.RBRACE) {
                break;
            }
            
            if !expect(ctx, TokenType.IDENTIFIER) {
                enforce_raw(false, "ERROR: Expected type name in overload mapping");
                return;
            }
            val type_token: Token = consume(ctx);
            append(type_names, type_token.value);
            // Support pointer types like "char*" by optionally consuming a STAR
            skip_whitespace(ctx);
            if expect(ctx, TokenType.STAR) {
                consume(ctx);
                // Append '*' to the last stored type name
                val last_idx: i32 = len(type_names) - 1;
                type_names.data[last_idx] = concat(type_names.data[last_idx], str("*"));
                skip_whitespace(ctx);
            }
            
            // Expect '=>'
            if !expect(ctx, TokenType.OPERATOR) {
                enforce_raw(false, "ERROR: Expected '=>' in overload mapping");
                return;
            }
            val op_token: Token = consume(ctx);
            if !equals_c(op_token.value, "=>") {
                enforce_raw(false, "ERROR: Expected '=>' in overload mapping");
                return;
            }
            skip_whitespace(ctx);
            
            if !expect(ctx, TokenType.IDENTIFIER) {
                enforce_raw(false, "ERROR: Expected target function name in overload mapping");
                return;
            }
            val first_target_token: Token = consume(ctx);
            mut target_name: string = first_target_token.value;
            skip_whitespace(ctx);
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type != TokenType.IDENTIFIER {
                    break;
                }
                val extra_tok: Token = consume(ctx);
                // Assume pieces belong to the same identifier and join with '_'
                target_name = concat(target_name, str("_"));
                target_name = concat(target_name, extra_tok.value);
                skip_whitespace(ctx);
            }
            append(target_funcs, target_name);
            
            if !expect(ctx, TokenType.SEMICOLON) {
                mut err: string = str("ERROR: Expected ';' after overload mapping, instead got ");
                if ctx.pos < len(ctx.tokens) {
                    err = concat(err, ctx.tokens.data[ctx.pos].value);
                } else {
                    err = concat(err, str("<eof>"));
                }
                enforce_raw(false, err.data);
                return;
            }
            consume(ctx);
        }
        
        if !expect(ctx, TokenType.RBRACE) {
            enforce_raw(false, "ERROR: Expected '}' after overload mappings");
            return;
        }
        consume(ctx);
        skip_whitespace(ctx);
        
        // Parse call expression: (expr)
        if !expect(ctx, TokenType.LPAREN) {
            enforce_raw(false, "ERROR: Expected '(' with call expression after overload block");
            return;
        }
        consume(ctx);
        
        mut call_expr: string = str("");
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            if expect(ctx, TokenType.RPAREN) {
                break;
            }
            
            val t: Token = consume(ctx);
            if t.token_type == TokenType.STR {
                call_expr = concat(call_expr, str("\""));
                call_expr = concat(call_expr, t.value);
                call_expr = concat(call_expr, str("\""));
            } elif t.token_type == TokenType.CHAR {
                call_expr = concat(call_expr, str("'"));
                call_expr = concat(call_expr, t.value);
                call_expr = concat(call_expr, str("'"));
            } else {
                call_expr = concat(call_expr, t.value);
            }
        }
        
        if !expect(ctx, TokenType.RPAREN) {
            enforce_raw(false, "ERROR: Expected ')' after overload call expression");
            return;
        }
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.SEMICOLON) {
            enforce_raw(false, "ERROR: Expected ';' after overload definition");
            return;
        }
        consume(ctx);
        
        mut overload_node: ASTNode;
        overload_node.node_type = str("Overload");
        overload_node.data.overload_node.name = overload_name.value;
        overload_node.data.overload_node.param_name = param_name;
        overload_node.data.overload_node.call_expr = call_expr;
        
        unsafe {
            val type_list_size: usize = C.sizeof(list(string));
            val heap_type_list: ref list(string) = cast[ref list(string)](C.malloc(type_list_size));
            if heap_type_list != nil {
                C.memcpy(heap_type_list, addr_of(type_names), type_list_size);
                overload_node.data.overload_node.type_names = heap_type_list;
            }
            
            val func_list_size: usize = C.sizeof(list(string));
            val heap_func_list: ref list(string) = cast[ref list(string)](C.malloc(func_list_size));
            if heap_func_list != nil {
                C.memcpy(heap_func_list, addr_of(target_funcs), func_list_size);
                overload_node.data.overload_node.target_functions = heap_func_list;
            }
        }
        
        add_child_to_ast(ast, overload_node);
        return;
    }
    
    if token_type == TokenType.PUB {
        ctx.pos++;  // Skip 'pub'
        skip_whitespace(ctx);
        parse_top_level(ctx, ast);
        return;
    }
    
    if token_type == TokenType.MACRO {
        ctx.pos++;  // Skip 'macro'
        skip_whitespace(ctx);
        
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
            ctx.pos++;
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LPAREN {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LPAREN {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RPAREN {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    if token_type == TokenType.OPAQUE {
        ctx.pos++;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            if ctx.tokens.data[ctx.pos].token_type == TokenType.SEMICOLON {
                ctx.pos++;
                break;
            }
            ctx.pos++;
        }
        return;
    }
    
    if token_type == TokenType.PLATFORM {
        ctx.pos++;
        skip_whitespace(ctx);
        
        if ctx.pos < len(ctx.tokens) {
            ctx.pos++;
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    // Unknown token type - skip it
    ctx.pos++;
}

/// Skip the whitespace and newline tokens
def skip_whitespace(ctx: ref ParserContext) {
    loop {
        if ctx.pos >= len(ctx.tokens) {
            break;
        }
        
        val token_type = ctx.tokens.data[ctx.pos].token_type;
        
        if token_type == TokenType.WHITESPACE or token_type == TokenType.NEWLINE {
            ctx.pos++;
        } else {
            break;
        }
    }
}

/// Peek at current token without advancing
def peek(ctx: ref ParserContext): Token {
    if ctx.pos < len(ctx.tokens) {
        return ctx.tokens.data[ctx.pos];
    }
    
    mut empty: Token;
    empty.token_type = TokenType.IDENTIFIER;
    empty.value = str("");
    empty.line = 0;
    empty.column = 0;
    return empty;
}

/// Consume current token and advance
def consume(ctx: ref ParserContext): Token {
    val token: Token = peek(ctx);
    ctx.pos = ctx.pos + 1;
    return token;
}

/// Check if current token matches expected type
def expect(ctx: ref ParserContext, expected_type: i32): bool {
    skip_whitespace(ctx);
    val token: Token = peek(ctx);
    return token.token_type == expected_type;
}

/// Parse a type specification (e.g., "i32", "ref string", "list(Token)")
def parse_type(ctx: ref ParserContext): string {
    skip_whitespace(ctx);
    
    if ctx.pos >= len(ctx.tokens) {
        enforce_raw(false, "Expected type but reached end of tokens");
        return str("");
    }
    
    mut ref_prefix: string = str("");
    
    loop {
        val token: Token = peek(ctx);
        if token.token_type == TokenType.REF {
            ref_prefix = concat_c(ref_prefix, "ref ");
            consume(ctx);
            skip_whitespace(ctx);
        } else {
            break;
        }
    }
    
    skip_whitespace(ctx);
    mut type_name: string = str("");
    val current_token: Token = peek(ctx);
    
    if current_token.token_type == TokenType.MODEL {
        consume(ctx);
        return concat_c(ref_prefix, "model");
    }
    
    if current_token.token_type == TokenType.IDENTIFIER {
        type_name = current_token.value;
        consume(ctx);
        
        // Handle list(ElementType) syntax
        if equals_c(type_name, "list") {
            skip_whitespace(ctx);
            
            if !expect(ctx, TokenType.LPAREN) {
                enforce_raw(false, "ERROR: Expected '(' after 'list'");
                return str("");
            }
            consume(ctx);
            
            skip_whitespace(ctx);
            val elem_token: Token = consume(ctx);
            val element_type: string = elem_token.value;
            
            skip_whitespace(ctx);
            if !expect(ctx, TokenType.RPAREN) {
                enforce_raw(false, "ERROR: Expected ')' after list element type");
                return str("");
            }
            consume(ctx);
            type_name = concat(element_type, str("[999]"));
        }

        loop {
            if expect(ctx, TokenType.LBRACKET) {
                consume(ctx);
                type_name = concat(type_name, str("["));
                
                loop {
                    val tok: Token = peek(ctx);
                    if tok.token_type == TokenType.RBRACKET {
                        break;
                    }
                    type_name = concat(type_name, tok.value);
                    consume(ctx);
                }
                
                if expect(ctx, TokenType.RBRACKET) {
                    consume(ctx);
                    type_name = concat(type_name, str("]"));
                }
            } else {
                break;
            }
        }
        
        loop {
            val tok: Token = peek(ctx);
            if tok.token_type == TokenType.OPERATOR and equals_c(tok.value, "*") {
                consume(ctx);
                type_name = concat(type_name, str("*"));
            } else {
                break;
            }
        }
    } else {
        enforce_raw(false, "ERROR: Invalid type specification");
        return str("");
    }
    
    if StringStringMap.contains(addr_of(g_type_aliases), type_name) {
        type_name = StringStringMap.get(addr_of(g_type_aliases), type_name);
    }
    
    return concat(ref_prefix, type_name);
}

/// Parse ref depth (e.g., "ref ref int" returns 2)
def parse_ref_depth(ctx: ref ParserContext): i32 {
    mut depth: i32 = 0;
    
    loop {
        skip_whitespace(ctx);
        
        if ctx.pos >= len(ctx.tokens) {
            break;
        }
        
        val token: Token = peek(ctx);
        if token.token_type == TokenType.REF {
            depth = depth + 1;
            consume(ctx);
        } else {
            break;
        }
    }
    
    return depth;
}

/// Parse function definition
def parse_function(ctx: ref ParserContext): ASTNode {
    mut func: ASTNode;
    func.node_type = str("Function");
    
    skip_whitespace(ctx);
    if ctx.pos >= len(ctx.tokens) or ctx.tokens.data[ctx.pos].token_type != TokenType.IDENTIFIER {
        enforce_raw(false, "ERROR: Expected function name after 'def'");
        return func;
    }
    
    mut func_name: string = ctx.tokens.data[ctx.pos].value;
    func.data.function.name = func_name;
    func.data.function.return_type = str("");
    func.data.function.is_public = false;
    ctx.pos++;
    
    skip_whitespace(ctx);

    // Handle function names that were split by the lexer into two IDENTs
    // when there is an implicit underscore, e.g. 'print' 'char' '(' for
    // a source name 'print_char('. If we see IDENT IDENT followed by a
    // '(' token (by value), merge the two identifiers with an underscore
    // for the function name.
    if ctx.pos + 1 < len(ctx.tokens) {
        if ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER and
           equals_c(ctx.tokens.data[ctx.pos + 1].value, "(") {
            mut merged: string = func_name;
            merged = concat(merged, str("_"));
            merged = concat(merged, ctx.tokens.data[ctx.pos].value);
            func_name = merged;
            func.data.function.name = merged;
            ctx.pos++;
            skip_whitespace(ctx);
        }
    }

    if !expect(ctx, TokenType.LPAREN) {
        println "DEBUG parse_function: missing '(' after function name";

        mut dbg: string = str("  func_name = ");
        dbg = concat(dbg, func_name);
        println dbg;
        mut buffer: char[64];
        dbg = str("  ctx.pos = ");
        dbg = concat_c(dbg, int_to_str(ctx.pos, buffer));
        dbg = concat(dbg, str(" / "));
        dbg = concat_c(dbg, int_to_str(len(ctx.tokens), buffer));
        println dbg;

        if ctx.pos < len(ctx.tokens) {
            dbg = str("  current token type = ");
            dbg = concat_c(dbg, int_to_str(ctx.tokens.data[ctx.pos].token_type, buffer));
            dbg = concat(dbg, str(", value = '"));
            dbg = concat(dbg, ctx.tokens.data[ctx.pos].value);
            dbg = concat(dbg, str("'"));
            println dbg;
        } else {
            println "  current token = <eof>";
        }

        mut start_dbg: i32 = ctx.pos - 5;
        if start_dbg < 0 {
            start_dbg = 0;
        }
        mut end_dbg: i32 = ctx.pos + 5;
        val total_tokens: i32 = len(ctx.tokens);
        if end_dbg > total_tokens {
            end_dbg = total_tokens;
        }
        println "  Surrounding tokens:";
        mut i_dbg: i32 = start_dbg;
        loop {
            if i_dbg >= end_dbg {
                break;
            }
            val tok_dbg: Token = ctx.tokens.data[i_dbg];
            mut buffer: char[64];

            dbg = str("    [");
            dbg = concat_c(dbg, int_to_str(i_dbg, buffer));

            dbg = concat(dbg, str("] type="));
            dbg = concat_c(dbg, int_to_str(tok_dbg.token_type, buffer));
            dbg = concat(dbg, str(", value='"));
            dbg = concat(dbg, tok_dbg.value);
            dbg = concat(dbg, str("'"));
            println dbg;
            i_dbg = i_dbg + 1;
        }

        mut err: string = str("ERROR: Expected '(' after function name");
        if ctx.pos < len(ctx.tokens) {
            err = concat(err, str(" instead got "));
            err = concat(err, ctx.tokens.data[ctx.pos].value);
        } else {
            err = concat(err, str(" instead got <eof>"));
        }
        err = concat(err, str(" in function "));
        err = concat(err, func_name);
        enforce_raw(false, err.data);
        return func;
    }
    consume(ctx);

    mut params: list(string);
    mut current_param: string = str("");
    mut paren_depth_params: i32 = 0;

    loop {
        if ctx.pos >= len(ctx.tokens) {
            break;
        }

        val t: Token = ctx.tokens.data[ctx.pos];

        if t.token_type == TokenType.RPAREN and paren_depth_params == 0 {
            mut trimmed: string = strip(current_param);
            if str_len(trimmed) > 0 {
                append(params, trimmed);
            }
            ctx.pos++;
            break;
        }

        if t.token_type == TokenType.LPAREN {
            paren_depth_params = paren_depth_params + 1;
            current_param = concat(current_param, t.value);
            consume(ctx);
            continue;
        }

        if t.token_type == TokenType.RPAREN {
            paren_depth_params = paren_depth_params - 1;
            current_param = concat(current_param, t.value);
            consume(ctx);
            continue;
        }

        if t.token_type == TokenType.COMMA and paren_depth_params == 0 {
            mut trimmed_param: string = strip(current_param);
            if str_len(trimmed_param) > 0 {
                append(params, trimmed_param);
            }
            current_param = str("");
            consume(ctx);
            continue;
        }

        if t.token_type == TokenType.WHITESPACE or t.token_type == TokenType.NEWLINE {
            consume(ctx);
            continue;
        }

        current_param = concat(current_param, t.value);
        consume(ctx);
    }

    // Store parameters on function node (if any)
    if len(params) > 0 {
        unsafe {
            val params_size: usize = C.sizeof(list(string));
            val heap_params: ref list(string) = cast[ref list(string)](C.malloc(params_size));
            if heap_params != nil {
                C.memcpy(heap_params, addr_of(params), params_size);
                func.data.function.params = heap_params;
            }
        }
    }

    skip_whitespace(ctx);
    if expect(ctx, TokenType.COLON) {
        consume(ctx);
        val return_type: string = parse_type(ctx);
        func.data.function.return_type = return_type;
    }
    
    skip_whitespace(ctx);
    if !expect(ctx, TokenType.LBRACE) {
        enforce_raw(false, "ERROR: Expected '{' after function declaration");
        return func;
    }
    consume(ctx);
    
    mut children: list(ASTNode);
    loop {
        if ctx.pos >= len(ctx.tokens) {
            break;
        }
        
        skip_whitespace(ctx);
        
        if ctx.pos >= len(ctx.tokens) {
            break;
        }
        
        if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
            ctx.pos++;
            break;
        }
        
        mut stmt: ASTNode = parse_statement_helper(ctx, addr_of(ctx.current_scope));
        if str_len(stmt.node_type) > 0 {
            append(children, stmt);
        }
    }
    
    unsafe {
        val list_size: usize = C.sizeof(list(ASTNode));
        val heap_list: ref list(ASTNode) = cast[ref list(ASTNode)](C.malloc(list_size));
        if heap_list != nil {
            C.memcpy(heap_list, addr_of(children), list_size);
            func.children = heap_list;
        }
    }
    
    return func;
}

/// Parse a single statement (helper for parsing function bodies, loops, etc.)
///
/// Returns an ASTNode for the statement, or null node for whitespace/newlines
def parse_statement_helper(ctx: ref ParserContext, scope: ref Scope): ASTNode {
    mut node: ASTNode;
    node.node_type = str("Empty");
    
    if ctx.pos >= len(ctx.tokens) {
        return node;
    }
    
    val token: Token = peek(ctx);
    val token_type: i32 = token.token_type;
    
    if token_type == TokenType.WHITESPACE or token_type == TokenType.NEWLINE {
        consume(ctx);
        return node;
    }
    
    // Handle BREAK
    if token_type == TokenType.BREAK {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.SEMICOLON) {
            enforce_raw(false, "ERROR: Expected ';' after break");
            return node;
        }
        consume(ctx);
        
        node.node_type = str("Break");
        return node;
    }
    
    // Handle CONTINUE
    if token_type == TokenType.CONTINUE {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.SEMICOLON) {
            enforce_raw(false, "ERROR: Expected ';' after continue");
            return node;
        }
        consume(ctx);
        
        node.node_type = str("Continue");
        return node;
    }
    
    // Handle ASSERT
    if token_type == TokenType.ASSERT {
        consume(ctx);
        skip_whitespace(ctx);
        
        mut has_parens: bool = false;
        if expect(ctx, TokenType.LPAREN) {
            has_parens = true;
            consume(ctx);
        }
        
        mut condition: string = str("");
        mut paren_depth: i32 = 0;
        
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            
            if t.token_type == TokenType.LPAREN {
                paren_depth = paren_depth + 1;
                condition = concat(condition, t.value);
                condition = concat(condition, str(" "));
            } elif t.token_type == TokenType.RPAREN {
                if paren_depth == 0 and has_parens {
                    break;
                }
                paren_depth = paren_depth - 1;
                condition = concat(condition, t.value);
                condition = concat(condition, str(" "));
            } elif t.token_type == TokenType.COMMA and paren_depth == 0 {
                break;
            } elif t.token_type != TokenType.WHITESPACE and t.token_type != TokenType.NEWLINE {
                if t.token_type == TokenType.STR {
                    condition = concat(condition, str("\""));
                    condition = concat(condition, t.value);
                    condition = concat(condition, str("\" "));
                } elif t.token_type == TokenType.CHAR {
                    condition = concat(condition, str("'"));
                    condition = concat(condition, t.value);
                    condition = concat(condition, str("' "));
                } else {
                    condition = concat(condition, t.value);
                    condition = concat(condition, str(" "));
                }
            }
            consume(ctx);
        }
        
        if !expect(ctx, TokenType.COMMA) {
            enforce_raw(false, "ERROR: Expected ',' after assert condition");
            return node;
        }
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.STR) {
            enforce_raw(false, "ERROR: Expected string message after comma in assert");
            return node;
        }
        val message_token: Token = consume(ctx);
        val message: string = message_token.value;
        skip_whitespace(ctx);
        
        if has_parens {
            if !expect(ctx, TokenType.RPAREN) {
                enforce_raw(false, "ERROR: Expected ')' after assert message");
                return node;
            }
            consume(ctx);
            skip_whitespace(ctx);
        }
        
        if !expect(ctx, TokenType.SEMICOLON) {
            enforce_raw(false, "ERROR: Expected ';' after assert statement");
            return node;
        }
        consume(ctx);
        
        node.node_type = str("Assert");
        node.data.assert_node.condition = condition;
        node.data.assert_node.message = message;
        return node;
    }
    
    // Handle RETURN
    if token_type == TokenType.RETURN {
        consume(ctx);
        skip_whitespace(ctx);
        
        mut expr: string = str("");
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.SEMICOLON {
                break;
            }
            if t.token_type == TokenType.STR {
                expr = concat(expr, str("\""));
                expr = concat(expr, t.value);
                expr = concat(expr, str("\" "));
            } elif t.token_type == TokenType.WHITESPACE or t.token_type == TokenType.NEWLINE {
                // Skip whitespace
            } else {
                expr = concat(expr, t.value);
                expr = concat(expr, str(" "));
            }
            consume(ctx);
        }
        
        if !expect(ctx, TokenType.SEMICOLON) {
            enforce_raw(false, "ERROR: Expected ';' after return");
            return node;
        }
        consume(ctx);
        
        node.node_type = str("Return");
        node.data.return_node.expression = expr;
        return node;
    }
    
    // Handle LOOP
    if token_type == TokenType.LOOP {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after loop");
            return node;
        }
        consume(ctx);
        
        // Skip loop body for now (just balance braces)
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Loop");
        return node;
    }
    
    // Handle SWITCH
    if token_type == TokenType.SWITCH {
        consume(ctx);
        skip_whitespace(ctx);
        
        mut switch_expr: string = str("");
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                break;
            }
            if t.token_type != TokenType.WHITESPACE and t.token_type != TokenType.NEWLINE {
                switch_expr = concat(switch_expr, t.value);
                switch_expr = concat(switch_expr, str(" "));
            }
            consume(ctx);
        }
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after switch expression");
            return node;
        }
        consume(ctx);
        
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Switch");
        return node;
    }
    
    // Handle IF
    if token_type == TokenType.IF {
        consume(ctx);
        skip_whitespace(ctx);
        
        mut condition: string = str("");
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                break;
            }
            if t.token_type != TokenType.WHITESPACE and t.token_type != TokenType.NEWLINE {

                // If we see a VAL token immediately followed by an IDENTIFIER token, it
                // may be an identifier like 'value' that was split into 'val' + 'ue'.
                //
                // In that case, concatenate the two pieces without an extra space so
                // the condition string becomes "value" instead of "val ue".

                if t.token_type == TokenType.VAL and ctx.pos + 1 < len(ctx.tokens) {
                    val next_tok: Token = ctx.tokens.data[ctx.pos + 1];
                    if next_tok.token_type == TokenType.IDENTIFIER {
                        mut merged: string = t.value;
                        merged = concat(merged, next_tok.value);
                        condition = concat(condition, merged);
                        condition = concat(condition, str(" "));
                        consume(ctx);
                        consume(ctx);
                        continue;
                    }
                }

                condition = concat(condition, t.value);
                condition = concat(condition, str(" "));
            }
            consume(ctx);
        }
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after if condition");
            return node;
        }
        consume(ctx);
        
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        // Handle elif clauses
        skip_whitespace(ctx);
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type != TokenType.ELIF {
                break;
            }
            
            consume(ctx);
            skip_whitespace(ctx);
            
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val elif_t: Token = peek(ctx);
                if elif_t.token_type == TokenType.LBRACE {
                    break;
                }
                consume(ctx);
            }
            
            if !expect(ctx, TokenType.LBRACE) {
                enforce_raw(false, "ERROR: Expected '{' after elif condition");
                return node;
            }
            consume(ctx);
            
            depth = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val elif_body_t: Token = peek(ctx);
                if elif_body_t.token_type == TokenType.LBRACE {
                    depth = depth + 1;
                } elif elif_body_t.token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        consume(ctx);
                        break;
                    }
                }
                consume(ctx);
            }
            
            skip_whitespace(ctx);
        }
        
        // Handle else clause
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) {
            val t: Token = peek(ctx);
            if t.token_type == TokenType.ELSE {
                consume(ctx);
                skip_whitespace(ctx);
                
                if !expect(ctx, TokenType.LBRACE) {
                    enforce_raw(false, "ERROR: Expected '{' after else");
                    return node;
                }
                consume(ctx);
                
                depth = 1;
                loop {
                    if ctx.pos >= len(ctx.tokens) {
                        break;
                    }
                    val else_t: Token = peek(ctx);
                    if else_t.token_type == TokenType.LBRACE {
                        depth = depth + 1;
                    } elif else_t.token_type == TokenType.RBRACE {
                        depth = depth - 1;
                        if depth == 0 {
                            consume(ctx);
                            break;
                        }
                    }
                    consume(ctx);
                }
            }
        }
        
        node.node_type = str("If");
        node.data.if_node.condition = condition;
        return node;
    }
    
    // Handle FOR
    if token_type == TokenType.FOR {
        consume(ctx);
        skip_whitespace(ctx);
        
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                break;
            }
            consume(ctx);
        }
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after for header");
            return node;
        }
        consume(ctx);
        
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("For");
        return node;
    }
    
    // Handle VAL and MUT VAL (variable declarations)
    if token_type == TokenType.VAL {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.IDENTIFIER) {
            enforce_raw(false, "ERROR: Expected identifier after 'val'");
            return node;
        }
        val var_name: Token = consume(ctx);
        skip_whitespace(ctx);

        mut type_name: string = str("i32");
        mut initializer: string = str("");

        if expect(ctx, TokenType.COLON) {
            consume(ctx);
            type_name = parse_type(ctx);
            skip_whitespace(ctx);
        }

        if expect(ctx, TokenType.OPERATOR) {
            val op_token: Token = peek(ctx);
            if equals_c(op_token.value, "=") {
                consume(ctx);
                skip_whitespace(ctx);

                loop {
                    if ctx.pos >= len(ctx.tokens) {
                        break;
                    }
                    val t: Token = peek(ctx);
                    if t.token_type == TokenType.SEMICOLON {
                        consume(ctx);
                        break;
                    }
                    if t.token_type == TokenType.STR {
                        initializer = concat(initializer, str("\""));
                        initializer = concat(initializer, t.value);
                        initializer = concat(initializer, str("\" "));
                    } elif t.token_type == TokenType.CHAR {
                        initializer = concat(initializer, str("'"));
                        initializer = concat(initializer, t.value);
                        initializer = concat(initializer, str("' "));
                    } elif t.token_type == TokenType.WHITESPACE or t.token_type == TokenType.NEWLINE {
                        // skip
                    } else {
                        initializer = concat(initializer, t.value);
                        initializer = concat(initializer, str(" "));
                    }
                    consume(ctx);
                }
            } else {
                loop {
                    if ctx.pos >= len(ctx.tokens) {
                        break;
                    }
                    val t: Token = peek(ctx);
                    if t.token_type == TokenType.SEMICOLON {
                        consume(ctx);
                        break;
                    }
                    consume(ctx);
                }
            }
        } else {
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.SEMICOLON {
                    consume(ctx);
                    break;
                }
                consume(ctx);
            }
        }

        node.node_type = str("Declaration");
        node.data.declaration.name = var_name.value;
        node.data.declaration.is_mutable = false;
        node.data.declaration.initializer = initializer;
        node.data.declaration.type_name = type_name;
        node.data.declaration.ref_depth = 0;
        return node;
    }
    
    if token_type == TokenType.MUT {
        consume(ctx); // Skip 'mut'
        skip_whitespace(ctx);
        
        if expect(ctx, TokenType.VAL) {
            consume(ctx);
            skip_whitespace(ctx);
        }
        
        if !expect(ctx, TokenType.IDENTIFIER) {
            enforce_raw(false, "ERROR: Expected identifier after 'mut'");
            return node;
        }
        val var_name: Token = consume(ctx);
        skip_whitespace(ctx);

        mut type_name: string = str("i32");
        mut initializer: string = str("");

        if expect(ctx, TokenType.COLON) {
            consume(ctx);
            type_name = parse_type(ctx);
            skip_whitespace(ctx);
        }

        if expect(ctx, TokenType.OPERATOR) {
            val op_token: Token = peek(ctx);
            if equals_c(op_token.value, "=") {
                consume(ctx); // Skip '='
                skip_whitespace(ctx);

                loop {
                    if ctx.pos >= len(ctx.tokens) {
                        break;
                    }
                    val t: Token = peek(ctx);
                    if t.token_type == TokenType.SEMICOLON {
                        consume(ctx);
                        break;
                    }
                    if t.token_type == TokenType.STR {
                        initializer = concat(initializer, str("\""));
                        initializer = concat(initializer, t.value);
                        initializer = concat(initializer, str("\" "));
                    } elif t.token_type == TokenType.CHAR {
                        initializer = concat(initializer, str("'"));
                        initializer = concat(initializer, t.value);
                        initializer = concat(initializer, str("' "));
                    } elif t.token_type == TokenType.WHITESPACE or t.token_type == TokenType.NEWLINE {
                        // skip
                    } else {
                        initializer = concat(initializer, t.value);
                        initializer = concat(initializer, str(" "));
                    }
                    consume(ctx);
                }
            } else {
                loop {
                    if ctx.pos >= len(ctx.tokens) {
                        break;
                    }
                    val t: Token = peek(ctx);
                    if t.token_type == TokenType.SEMICOLON {
                        consume(ctx);
                        break;
                    }
                    consume(ctx);
                }
            }
        } else {
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.SEMICOLON {
                    consume(ctx);
                    break;
                }
                consume(ctx);
            }
        }

        node.node_type = str("Declaration");
        node.data.declaration.name = var_name.value;
        node.data.declaration.is_mutable = true;
        node.data.declaration.initializer = initializer;
        node.data.declaration.type_name = type_name;
        node.data.declaration.ref_depth = 0;
        return node;
    }
    
    // Handle IDENTIFIER (function calls, assignments, etc.)
    if token_type == TokenType.IDENTIFIER {
        val ident_token: Token = consume(ctx);
        val ident_name: string = ident_token.value;
        skip_whitespace(ctx);
        
        if ctx.pos >= len(ctx.tokens) {
            return node;
        }
        
        val next_token: Token = peek(ctx);
        
        if next_token.token_type == TokenType.LPAREN {
            consume(ctx);            
            mut paren_depth: i32 = 1;
            mut args_str: string = str("");
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.LPAREN {
                    paren_depth = paren_depth + 1;
                    args_str = concat(args_str, str("("));
                } elif t.token_type == TokenType.RPAREN {
                    paren_depth = paren_depth - 1;
                    if paren_depth == 0 {
                        consume(ctx);
                        break;
                    }
                    args_str = concat(args_str, str(")"));
                } elif t.token_type == TokenType.STR {
                    args_str = concat(args_str, str("\""));
                    args_str = concat(args_str, t.value);
                    args_str = concat(args_str, str("\""));
                } elif t.token_type == TokenType.CHAR {
                    args_str = concat(args_str, str("'"));
                    args_str = concat(args_str, t.value);
                    args_str = concat(args_str, str("'"));
                } elif t.token_type == TokenType.WHITESPACE or t.token_type == TokenType.NEWLINE {
                    // normalize to single space
                    args_str = concat(args_str, str(" "));
                } else {
                    args_str = concat(args_str, t.value);
                }
                consume(ctx);
            }
            
            skip_whitespace(ctx);
            
            if expect(ctx, TokenType.SEMICOLON) {
                consume(ctx);
            }
            
            node.node_type = str("FunctionCall");
            node.data.func_call.function_name = ident_name;

            mut args_list: list(string);
            val trimmed_args: string = strip(args_str);
            if str_len(trimmed_args) > 0 {
                append(args_list, trimmed_args);
            }

            unsafe {
                val list_size: usize = C.sizeof(list(string));
                mut heap_list: ref list(string) = cast[ref list(string)](C.malloc(list_size));
                if heap_list != nil {
                    C.memcpy(heap_list, addr_of(args_list), list_size);
                    node.data.func_call.args = heap_list;
                }
            }
            return node;
        }
        
        if next_token.token_type == TokenType.LBRACKET {
            consume(ctx); // Skip '['
            skip_whitespace(ctx);
            
            mut index_expr: string = str("");
            mut bracket_depth: i32 = 0;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.LBRACKET {
                    bracket_depth = bracket_depth + 1;
                    index_expr = concat(index_expr, t.value);
                    index_expr = concat(index_expr, str(" "));
                } elif t.token_type == TokenType.RBRACKET {
                    if bracket_depth == 0 {
                        break;
                    }
                    bracket_depth = bracket_depth - 1;
                    index_expr = concat(index_expr, t.value);
                    index_expr = concat(index_expr, str(" "));
                } elif t.token_type != TokenType.WHITESPACE and t.token_type != TokenType.NEWLINE {
                    index_expr = concat(index_expr, t.value);
                    index_expr = concat(index_expr, str(" "));
                }
                consume(ctx);
            }
            
            if !expect(ctx, TokenType.RBRACKET) {
                enforce_raw(false, "ERROR: Expected ']' after array index");
                return node;
            }
            consume(ctx);
            skip_whitespace(ctx);
            
            mut index2_expr: string = str("");
            if expect(ctx, TokenType.LBRACKET) {
                consume(ctx); // Skip '['
                skip_whitespace(ctx);
                
                bracket_depth = 0;
                loop {
                    if ctx.pos >= len(ctx.tokens) {
                        break;
                    }
                    val t: Token = peek(ctx);
                    if t.token_type == TokenType.LBRACKET {
                        bracket_depth = bracket_depth + 1;
                        index2_expr = concat(index2_expr, t.value);
                        index2_expr = concat(index2_expr, str(" "));
                    } elif t.token_type == TokenType.RBRACKET {
                        if bracket_depth == 0 {
                            break;
                        }
                        bracket_depth = bracket_depth - 1;
                        index2_expr = concat(index2_expr, t.value);
                        index2_expr = concat(index2_expr, str(" "));
                    } elif t.token_type != TokenType.WHITESPACE and t.token_type != TokenType.NEWLINE {
                        index2_expr = concat(index2_expr, t.value);
                        index2_expr = concat(index2_expr, str(" "));
                    }
                    consume(ctx);
                }
                
                if !expect(ctx, TokenType.RBRACKET) {
                    enforce_raw(false, "ERROR: Expected ']' after second array index");
                    return node;
                }
                consume(ctx);
                skip_whitespace(ctx);
            }
            
            // Check if this is array assignment: array[index] = value
            if expect(ctx, TokenType.OPERATOR) {
                val op_token: Token = peek(ctx);
                if equals_c(op_token.value, "=") {
                    consume(ctx); // Skip '='
                    skip_whitespace(ctx);
                    
                    mut value_expr: string = str("");
                    loop {
                        if ctx.pos >= len(ctx.tokens) {
                            break;
                        }
                        val t: Token = peek(ctx);
                        if t.token_type == TokenType.SEMICOLON {
                            consume(ctx);
                            break;
                        }
                        if t.token_type == TokenType.STR {
                            value_expr = concat(value_expr, str("\""));
                            value_expr = concat(value_expr, t.value);
                            value_expr = concat(value_expr, str("\" "));
                        } elif t.token_type == TokenType.WHITESPACE or t.token_type == TokenType.NEWLINE {
                        } else {
                            value_expr = concat(value_expr, t.value);
                            value_expr = concat(value_expr, str(" "));
                        }
                        consume(ctx);
                    }
                    
                    node.node_type = str("ArrayAssign");
                    node.data.array_assign.array_name = ident_name;
                    node.data.array_assign.index = index_expr;
                    node.data.array_assign.index2 = index2_expr;
                    node.data.array_assign.value = value_expr;
                    return node;
                }
            }
            
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.SEMICOLON {
                    consume(ctx);
                    break;
                }
                consume(ctx);
            }
            
            node.node_type = str("ArrayAccess");
            node.data.array_access.array_name = ident_name;
            node.data.array_access.index = index_expr;
            node.data.array_access.index2 = index2_expr;
            return node;
        }
        
        if next_token.token_type == TokenType.DOT {
            consume(ctx); // Skip '.'
            skip_whitespace(ctx);
            
            if !expect(ctx, TokenType.IDENTIFIER) {
                enforce_raw(false, "ERROR: Expected member name after '.'");
                return node;
            }
            val member_token: Token = consume(ctx);
            val member_name: string = member_token.value;
            skip_whitespace(ctx);

            if expect(ctx, TokenType.LPAREN) {
                consume(ctx); // skip '('
                mut paren_depth2: i32 = 1;
                mut args_str2: string = str("");
                loop {
                    if ctx.pos >= len(ctx.tokens) {
                        break;
                    }
                    val t2: Token = peek(ctx);
                    if t2.token_type == TokenType.LPAREN {
                        paren_depth2 = paren_depth2 + 1;
                        args_str2 = concat(args_str2, str("("));
                    } elif t2.token_type == TokenType.RPAREN {
                        paren_depth2 = paren_depth2 - 1;
                        if paren_depth2 == 0 {
                            consume(ctx);
                            break;
                        }
                        args_str2 = concat(args_str2, str(")"));
                    } elif t2.token_type == TokenType.STR {
                        args_str2 = concat(args_str2, str("\""));
                        args_str2 = concat(args_str2, t2.value);
                        args_str2 = concat(args_str2, str("\""));
                    } elif t2.token_type == TokenType.CHAR {
                        args_str2 = concat(args_str2, str("'"));
                        args_str2 = concat(args_str2, t2.value);
                        args_str2 = concat(args_str2, str("'"));
                    } elif t2.token_type == TokenType.WHITESPACE or t2.token_type == TokenType.NEWLINE {
                        args_str2 = concat(args_str2, str(" "));
                    } else {
                        args_str2 = concat(args_str2, t2.value);
                    }
                    consume(ctx);
                }

                skip_whitespace(ctx);
                if expect(ctx, TokenType.SEMICOLON) {
                    consume(ctx);
                }

                node.node_type = str("FunctionCall");
                mut full_name: string = ident_name;

                if equals_c(ident_name, "C") {
                    full_name = member_name;
                } else {
                    full_name = concat(full_name, str("."));
                    full_name = concat(full_name, member_name);
                }
                node.data.func_call.function_name = full_name;

                mut args_list2: list(string);
                val trimmed2: string = strip(args_str2);
                if str_len(trimmed2) > 0 {
                    append(args_list2, trimmed2);
                }

                unsafe {
                    val list_size2: usize = C.sizeof(list(string));
                    mut heap_list2: ref list(string) = cast[ref list(string)](C.malloc(list_size2));
                    if heap_list2 != nil {
                        C.memcpy(heap_list2, addr_of(args_list2), list_size2);
                        node.data.func_call.args = heap_list2;
                    }
                }
                return node;
            }
            
            if expect(ctx, TokenType.OPERATOR) {
                val op_token: Token = peek(ctx);
                if equals_c(op_token.value, "=") {
                    consume(ctx); // Skip '='
                    skip_whitespace(ctx);
                    
                    // Collect the value expression until semicolon
                    mut value_expr: string = str("");
                    loop {
                        if ctx.pos >= len(ctx.tokens) {
                            break;
                        }
                        val t: Token = peek(ctx);
                        if t.token_type == TokenType.SEMICOLON {
                            consume(ctx);
                            break;
                        }
                        if t.token_type == TokenType.STR {
                            value_expr = concat(value_expr, str("\""));
                            value_expr = concat(value_expr, t.value);
                            value_expr = concat(value_expr, str("\" "));
                        } elif t.token_type == TokenType.WHITESPACE or t.token_type == TokenType.NEWLINE {
                            // Skip whitespace in value
                        } else {
                            value_expr = concat(value_expr, t.value);
                            value_expr = concat(value_expr, str(" "));
                        }
                        consume(ctx);
                    }
                    
                    node.node_type = str("MemberAccess");
                    node.data.member_access.object_name = ident_name;
                    node.data.member_access.member_name = member_name;
                    node.data.member_access.value = value_expr;
                    return node;
                }
            }
            
            // Check for: member increment/decrement, so obj.field++ or obj.field--
            if expect(ctx, TokenType.INCREMENT) or expect(ctx, TokenType.DECREMENT) {
                val inc_dec_token: Token = peek(ctx);
                val is_inc: bool = inc_dec_token.token_type == TokenType.INCREMENT;
                consume(ctx);
                skip_whitespace(ctx);
                
                if !expect(ctx, TokenType.SEMICOLON) {
                    enforce_raw(false, "ERROR: Expected ';' after member increment/decrement");
                    return node;
                }
                consume(ctx);
                
                node.node_type = str("MemberIncDec");
                node.data.member_inc_dec.object_name = ident_name;
                node.data.member_inc_dec.member_name = member_name;
                node.data.member_inc_dec.is_increment = is_inc;
                return node;
            }
            
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.SEMICOLON {
                    consume(ctx);
                    break;
                }
                consume(ctx);
            }
            
            node.node_type = str("MemberAccess");
            node.data.member_access.object_name = ident_name;
            node.data.member_access.member_name = member_name;
            node.data.member_access.value = str("");
            return node;
        }
        
        if next_token.token_type == TokenType.OPERATOR and equals_c(next_token.value, "=") {
            println "[DEBUG] parse_statement_helper: entering Assignment branch";
            println "[DEBUG]   ident_name:";
            println ident_name;

            consume(ctx); // Skip '='
            skip_whitespace(ctx);

            mut expr: string = str("");
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    println "[DEBUG]   reached end of tokens while collecting RHS";
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.SEMICOLON {
                    println "[DEBUG]   encountered ';' terminating RHS";
                    consume(ctx);
                    break;
                }

                // Per-token debug for RHS
                println "[DEBUG]   RHS token type:";
                println t.token_type;
                println "[DEBUG]   RHS token value:";
                println t.value;

                if t.token_type == TokenType.STR {
                    expr = concat(expr, str("\""));
                    expr = concat(expr, t.value);
                    expr = concat(expr, str("\" "));
                } elif t.token_type == TokenType.CHAR {
                    expr = concat(expr, str("'"));
                    expr = concat(expr, t.value);
                    expr = concat(expr, str("' "));
                } elif t.token_type == TokenType.WHITESPACE or t.token_type == TokenType.NEWLINE {
                    // I dont give a shit
                } else {
                    expr = concat(expr, t.value);
                    expr = concat(expr, str(" "));
                }
                consume(ctx);
            }

            println "[DEBUG]   final RHS expr:";
            println expr;

            node.node_type = str("Assignment");
            node.data.assignment.variable = ident_name;
            node.data.assignment.expression = expr;
            return node;
        }
        
        // Handle: INCREMENT and DECREMENT: variable++ or variable--
        if next_token.token_type == TokenType.INCREMENT or next_token.token_type == TokenType.DECREMENT {
            val is_inc: bool = next_token.token_type == TokenType.INCREMENT;
            consume(ctx);
            skip_whitespace(ctx);
            
            if !expect(ctx, TokenType.SEMICOLON) {
                enforce_raw(false, "ERROR: Expected ';' after increment/decrement");
                return node;
            }
            consume(ctx);
            
            node.node_type = str("IncDec");
            node.data.inc_dec.variable = ident_name;
            node.data.inc_dec.is_increment = is_inc;
            return node;
        }
        
        // Function call without parentheses (Axe syntax sugar): e.g. println "hello"
        // Consume until semicolon
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.SEMICOLON {
                consume(ctx);
                break;
            }
            consume(ctx);
        }
        
        node.node_type = str("FunctionCall");
        return node;
    }
    
    // Handle PLATFORM
    if token_type == TokenType.PLATFORM {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.WINDOWS) and !expect(ctx, TokenType.POSIX) {
            enforce_raw(false, "ERROR: Expected 'windows' or 'posix' after 'platform'");
            return node;
        }
        val platform_token: Token = consume(ctx);
        val platform_name: string = platform_token.value;
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after platform name");
            return node;
        }
        consume(ctx);
        
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Platform");
        node.data.platform_node.platform_name = platform_name;
        return node;
    }
    
    // Handle PARALLEL
    if token_type == TokenType.PARALLEL {
        consume(ctx);
        skip_whitespace(ctx);
        
        if expect(ctx, TokenType.FOR) {
            consume(ctx);
            skip_whitespace(ctx);
            
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.LBRACE {
                    break;
                }
                consume(ctx);
            }
            
            if !expect(ctx, TokenType.LBRACE) {
                enforce_raw(false, "ERROR: Expected '{' after parallel for header");
                return node;
            }
            consume(ctx);
            
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.LBRACE {
                    depth = depth + 1;
                } elif t.token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        consume(ctx);
                        break;
                    }
                }
                consume(ctx);
            }
            
            node.node_type = str("ParallelFor");
            return node;
        }
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after 'parallel'");
            return node;
        }
        consume(ctx);
        
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Parallel");
        return node;
    }
    
    // Handle SINGLE
    if token_type == TokenType.SINGLE {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after 'single'");
            return node;
        }
        consume(ctx);
        
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Single");
        return node;
    }
    
    if token_type == TokenType.UNSAFE {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after 'unsafe'");
            return node;
        }
        consume(ctx); // Skip '{'
        
        mut body: list(ASTNode);
        
        loop {
            skip_whitespace(ctx);
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                consume(ctx); // Skip '}'
                break;
            }
            
            mut stmt: ASTNode = parse_statement_helper(ctx, addr_of(ctx.current_scope));
            if str_len(stmt.node_type) > 0 {
                append(body, stmt);
            }
        }
        
        node.node_type = str("Unsafe");

        unsafe {
            val list_size_ast: usize = C.sizeof(list(ASTNode));
            mut heap_body: ref list(ASTNode) = cast[ref list(ASTNode)](C.malloc(list_size_ast));
            if heap_body != nil {
                C.memcpy(heap_body, addr_of(body), list_size_ast);
                node.data.unsafe_node.body = heap_body;
            }
        }
        return node;
    }
    
    // Handle RAW (only in .axec files)
    if token_type == TokenType.RAW {
        if !ctx.is_axec {
            enforce_raw(false, "ERROR: Raw C blocks are only allowed in .axec files");
            return node;
        }
        
        consume(ctx); // Skip 'raw'
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after 'raw'");
            return node;
        }
        consume(ctx);
        
        // Collect raw code until closing brace
        mut raw_code: string = str("");
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.RBRACE {
                consume(ctx);
                break;
            }
            raw_code = concat(raw_code, t.value);
            consume(ctx);
        }
        
        node.node_type = str("RawC");
        node.data.raw_c.code = raw_code;
        return node;
    }
    
    // Handle OPAQUE (only in .axec files)
    if token_type == TokenType.OPAQUE {
        consume(ctx); // Skip 'opaque'
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after 'opaque'");
            return node;
        }
        consume(ctx);
        
        // Collect opaque type names
        mut type_names: list(string);
        loop {
            skip_whitespace(ctx);
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.RBRACE {
                consume(ctx);
                break;
            }
            if t.token_type == TokenType.IDENTIFIER {
                append(type_names, t.value);
                consume(ctx);
            } elif t.token_type == TokenType.SEMICOLON or t.token_type == TokenType.COMMA {
                consume(ctx);
            } else {
                consume(ctx);
            }
        }
        
        skip_whitespace(ctx);
        
        node.node_type = str("Opaque");
        
        unsafe {
            val list_size: usize = C.sizeof(list(string));
            mut heap_list: ref list(string) = cast[ref list(string)](C.malloc(list_size));
            if heap_list != nil {
                C.memcpy(heap_list, addr_of(type_names), list_size);
                node.data.opaque_node.type_names = heap_list;
            }
        }
        
        return node;
    }
    
    // Handle EXTERN (only in .axec files)
    if token_type == TokenType.EXTERN {
        consume(ctx); // Skip 'extern'
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.DEF) {
            enforce_raw(false, "ERROR: Expected 'def' after 'extern'");
            return node;
        }
        consume(ctx);
        skip_whitespace(ctx);
        
        // Get function name
        if !expect(ctx, TokenType.IDENTIFIER) {
            enforce_raw(false, "ERROR: Expected function name after 'extern def'");
            return node;
        }
        val func_name_token: Token = consume(ctx);
        val func_name: string = func_name_token.value;
        skip_whitespace(ctx);
        
        // Skip parameters and return type until semicolon
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.SEMICOLON {
                consume(ctx);
                break;
            }
            consume(ctx);
        }
        
        node.node_type = str("Extern");
        node.data.extern_node.function_name = func_name;
        return node;
    }
    
    if token_type == TokenType.USE {
        consume(ctx); // Skip 'use'
        skip_whitespace(ctx);
        
        if expect(ctx, TokenType.EXTERNAL) {
            consume(ctx);
            skip_whitespace(ctx);
            
            if !expect(ctx, TokenType.LPAREN) {
                enforce_raw(false, "ERROR: Expected '(' after 'use external'");
                return node;
            }
            consume(ctx);
            
            if !expect(ctx, TokenType.STR) {
                enforce_raw(false, "ERROR: Expected string literal for header file");
                return node;
            }
            val header_token: Token = consume(ctx);
            val header_file: string = header_token.value;
            
            if !expect(ctx, TokenType.RPAREN) {
                enforce_raw(false, "ERROR: Expected ')' after header file");
                return node;
            }
            consume(ctx);
            skip_whitespace(ctx);
            
            if !expect(ctx, TokenType.SEMICOLON) {
                enforce_raw(false, "ERROR: Expected ';' after external import");
                return node;
            }
            consume(ctx);
            
            node.node_type = str("ExternalImport");
            node.data.external_import.header_file = header_file;
            return node;
        }
        
        mut module_name: string = str("");
        
        loop {
            if expect(ctx, TokenType.DOT) {
                val dot_tok: Token = peek(ctx);
                consume(ctx);
                
                if expect(ctx, TokenType.DOT) {
                    consume(ctx);
                    if expect(ctx, TokenType.SLASH) {
                        consume(ctx);
                        module_name = concat(module_name, str("../"));
                        continue;
                    }
                } elif expect(ctx, TokenType.SLASH) {
                    consume(ctx);
                    module_name = concat(module_name, str("./"));
                    continue;
                }
            }
            break;
        }
        
        // Parse module path (e.g., std.io or std/maps)
        if !expect(ctx, TokenType.IDENTIFIER) {
            enforce_raw(false, "ERROR: Expected module name after 'use'");
            return node;
        }
        val first_ident: Token = consume(ctx);
        module_name = concat(module_name, first_ident.value);
        
        loop {
            skip_whitespace(ctx);
            if expect(ctx, TokenType.DOT) {
                consume(ctx);
                module_name = concat(module_name, str("."));
                
                if !expect(ctx, TokenType.IDENTIFIER) {
                    enforce_raw(false, "ERROR: Expected identifier after '.' in module path");
                    return node;
                }
                val ident: Token = consume(ctx);
                module_name = concat(module_name, ident.value);
            } elif expect(ctx, TokenType.SLASH) {
                consume(ctx);
                module_name = concat(module_name, str("/"));
                
                if !expect(ctx, TokenType.IDENTIFIER) {
                    enforce_raw(false, "ERROR: Expected identifier after '/' in module path");
                    return node;
                }
                val ident: Token = consume(ctx);
                module_name = concat(module_name, ident.value);
            } else {
                break;
            }
        }
        
        skip_whitespace(ctx);
        
        // Check for import all syntax: use module;
        if expect(ctx, TokenType.SEMICOLON) {
            consume(ctx);
            node.node_type = str("Use");
            node.data.use_node.module_name = module_name;
            node.data.use_node.import_all = true;
            return node;
        }
        
        // Parse selective imports: use module (item1, item2);
        if !expect(ctx, TokenType.LPAREN) {
            enforce_raw(false, "ERROR: Expected '(' or ';' after module name");
            return node;
        }
        consume(ctx);
        
        mut imports: list(string);
        loop {
            skip_whitespace(ctx);
            if expect(ctx, TokenType.RPAREN) {
                break;
            }
            
            if expect(ctx, TokenType.IDENTIFIER) {
                val import_token: Token = consume(ctx);
                append(imports, import_token.value);
            } elif expect(ctx, TokenType.COMMA) {
                consume(ctx);
            } else {
                enforce_raw(false, "ERROR: Expected identifier or ',' in use statement");
                return node;
            }
        }
        
        if !expect(ctx, TokenType.RPAREN) {
            enforce_raw(false, "ERROR: Expected ')' after imports");
            return node;
        }
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.SEMICOLON) {
            enforce_raw(false, "ERROR: Expected ';' after use statement");
            return node;
        }
        consume(ctx);
        
        node.node_type = str("Use");
        node.data.use_node.module_name = module_name;
        
        // Heap-allocate the imports list so it persists after function returns
        // The list struct contains data inline, so we just copy the whole struct
        unsafe {
            val list_size: usize = C.sizeof(list(string));
            mut heap_list: ref list(string) = cast[ref list(string)](C.malloc(list_size));
            if heap_list != nil {
                C.memcpy(heap_list, addr_of(imports), list_size);
                node.data.use_node.imports = heap_list;
            }
        }
        
        node.data.use_node.import_all = false;
        return node;
    }
    
    // Handle CASE (within switch statements)
    if token_type == TokenType.CASE {
        println "[DEBUG] Parsing CASE statement";
        consume(ctx); // Skip 'case'
        println "[DEBUG] Consumed 'case' token";
        skip_whitespace(ctx);
        println "[DEBUG] Skipped whitespace after 'case'";
        
        // Collect case value until '{'
        mut case_value: string = str("");
        println "[DEBUG] Starting to collect case value";
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                break;
            }
            if t.token_type != TokenType.WHITESPACE and t.token_type != TokenType.NEWLINE {
                case_value = concat(case_value, t.value);
                case_value = concat(case_value, str(" "));
            }
            consume(ctx);
        }
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after case value");
            return node;
        }
        consume(ctx);
        
        // Skip case body
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Case");
        node.data.case_node.value = case_value;
        node.data.case_node.is_default = false;
        return node;
    }
    
    // Handle DEFAULT (within switch statements)
    if token_type == TokenType.DEFAULT {
        consume(ctx); // Skip 'default'
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after default");
            return node;
        }
        consume(ctx);
        
        // Skip default body
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Case");
        node.data.case_node.value = str("");
        node.data.case_node.is_default = true;
        return node;
    }
    
    // For now, skip unknown tokens
    consume(ctx);
    return node;
}

test {
    initialize_all();
    
    println "\nTest 1: parse_type with simple type";
    mut tokens1: list(Token) = lex(str("i32"));
    mut ctx1: ParserContext;
    ctx1.tokens = addr_of(tokens1);
    ctx1.pos = 0;
    mut type1: string = parse_type(addr_of(ctx1));
    assert equals_c(type1, "i32"), "Expected i32.";

    println "\nTest 2: skip_whitespace";
    mut tokens2: list(Token) = lex(str("   \n  \t  i32"));
    mut ctx2: ParserContext;
    ctx2.tokens = addr_of(tokens2);
    ctx2.pos = 0;
    mut pos_before: i32 = ctx2.pos;
    skip_whitespace(addr_of(ctx2));
    assert ctx2.pos > pos_before, "Expected position to advance after skipping whitespace";

    println "\nTest 3: peek and consume";
    mut tokens3: list(Token) = lex(str("identifier"));
    mut ctx3: ParserContext;
    ctx3.tokens = addr_of(tokens3);
    ctx3.pos = 0;
    mut peeked: Token = peek(addr_of(ctx3));
    mut pos_after_peek: i32 = ctx3.pos;
    mut consumed: Token = consume(addr_of(ctx3));
    mut pos_after_consume: i32 = ctx3.pos;
    assert pos_after_peek == 0 and pos_after_consume == 1, "Expected position to advance after consume";

    println "\nTest 4: expect";
    mut tokens4: list(Token) = lex(str("def function_name"));
    mut ctx4: ParserContext;
    ctx4.tokens = addr_of(tokens4);
    ctx4.pos = 0;
    assert expect(addr_of(ctx4), TokenType.DEF), "Expected to find 'def' token";

    println "\nTest 5: parse_type with ref type";
    mut tokens5: list(Token) = lex(str("ref i32"));
    mut ctx5: ParserContext;
    ctx5.tokens = addr_of(tokens5);
    ctx5.pos = 0;
    mut type5: string = parse_type(addr_of(ctx5));
    assert str_len(type5) > 0, "Expected non-empty type string for 'ref i32'";
    assert str_contains_c(type5, "i32"), "Expected type to contain 'i32'";

    println "\nTest 6: parse_type with list type";
    mut tokens6: list(Token) = lex(str("list(Token)"));
    mut ctx6: ParserContext;
    ctx6.tokens = addr_of(tokens6);
    ctx6.pos = 0;
    mut type6: string = parse_type(addr_of(ctx6));
    assert str_len(type6) > 0, "Expected non-empty type for list(Token)";
    assert str_contains_c(type6, "Token"), "Expected type to contain 'Token'";

    println "\nTest 7: parse simple function with parse_function";
    mut tokens7: list(Token) = lex(str("foo(): i32 { return 42; }"));
    mut ctx7: ParserContext;
    ctx7.tokens = addr_of(tokens7);
    ctx7.pos = 0;
    mut func7: ASTNode = parse_function(addr_of(ctx7));
    assert equals_c(func7.node_type, "Function"), "Expected Function node type";

    println "\nTest 8: parse function with parameters";
    mut tokens8: list(Token) = lex(str("add(a: i32): i32 { return a; }"));
    mut ctx8: ParserContext;
    ctx8.tokens = addr_of(tokens8);
    ctx8.pos = 0;
    mut func8: ASTNode = parse_function(addr_of(ctx8));
    assert equals_c(func8.node_type, "Function"), "Expected Function node for function with params";

    println "\nTest 9: parse full program with def main";
    mut tokens9: list(Token) = lex(str("def main() { }"));
    mut empty_module: string = str("");
    mut ast9: ASTNode = parse(addr_of(tokens9), false, false, empty_module);
    assert equals_c(ast9.node_type, "Program"), "Expected Program AST node";

    println "\nTest 10: parse program with model definition";
    mut tokens10: list(Token) = lex(str("model Point { x: i32 } def main() { }"));
    mut ast10: ASTNode = parse(addr_of(tokens10), false, false, str(""));
    assert equals_c(ast10.node_type, "Program"), "Expected Program node with model";

    println "\nTest 11: parse program with enum definition";
    mut tokens11: list(Token) = lex(str("enum Color { Red } def main() { }"));
    mut ast11: ASTNode = parse(addr_of(tokens11), false, false, str(""));
    assert equals_c(ast11.node_type, "Program"), "Expected Program node with enum";

    println "\nTest 12: parse program with use statement";
    mut tokens12: list(Token) = lex(str("use std.io; def main() { }"));
    mut ast12: ASTNode = parse(addr_of(tokens12), false, false, str(""));
    assert equals_c(ast12.node_type, "Program"), "Expected Program node with use statement";

    println "\nTest 13: parse program with global val";
    mut tokens13: list(Token) = lex(str("val CONSTANT: i32 = 42; def main() { }"));
    mut ast13: ASTNode = parse(addr_of(tokens13), false, false, str(""));
    assert equals_c(ast13.node_type, "Program"), "Expected Program node with global val";

    println "\nTest 14: parse program with mut val";
    mut tokens14: list(Token) = lex(str("mut val counter: i32 = 0; def main() { }"));
    mut ast14: ASTNode = parse(addr_of(tokens14), false, false, str(""));
    assert equals_c(ast14.node_type, "Program"), "Expected Program node with mut val";

    println "\nTest 15: parse program with pub function";
    mut tokens15: list(Token) = lex(str("pub def helper() { } def main() { }"));
    mut ast15: ASTNode = parse(addr_of(tokens15), false, false, str(""));
    assert equals_c(ast15.node_type, "Program"), "Expected Program node with pub function";

    println "\nTest 16: parse empty test block";
    mut tokens16: list(Token) = lex(str("test { }"));
    mut ast16: ASTNode = parse(addr_of(tokens16), false, false, str(""));
    assert equals_c(ast16.node_type, "Program"), "Expected Program node with test block";

    println "\nTest 17: parse_type with pointer syntax";
    mut tokens17: list(Token) = lex(str("i32*"));
    mut ctx17: ParserContext;
    ctx17.tokens = addr_of(tokens17);
    ctx17.pos = 0;
    mut type17: string = parse_type(addr_of(ctx17));
    assert str_len(type17) > 0, "Expected non-empty type for i32*";
    assert str_contains_c(type17, "i32"), "Expected type to contain 'i32'";

    println "\nTest 18: parse multiple functions";
    mut tokens18: list(Token) = lex(str("def foo() { } def bar() { } def main() { }"));
    mut ast18: ASTNode = parse(addr_of(tokens18), false, false, str(""));
    assert equals_c(ast18.node_type, "Program"), "Expected Program node with multiple functions";

    println "\nTest 19: parse_statement_helper with break";
    mut tokens19: list(Token) = lex(str("break;"));
    mut ctx19: ParserContext;
    ctx19.tokens = addr_of(tokens19);
    ctx19.pos = 0;
    ctx19.is_axec = false;
    ctx19.check_entry_point = false;
    ctx19.current_module = str("");
    mut stmt19: ASTNode = parse_statement_helper(addr_of(ctx19), addr_of(ctx19.current_scope));
    assert equals_c(stmt19.node_type, "Break"), "Expected Break node";

    println "\nTest 20: parse_statement_helper with return";
    mut tokens20: list(Token) = lex(str("return 42;"));
    mut ctx20: ParserContext;
    ctx20.tokens = addr_of(tokens20);
    ctx20.pos = 0;
    ctx20.is_axec = false;
    mut stmt20: ASTNode = parse_statement_helper(addr_of(ctx20), addr_of(ctx20.current_scope));
    assert equals_c(stmt20.node_type, "Return"), "Expected Return node";
    assert str_contains_c(stmt20.data.return_node.expression, "42"), "Expected return expression to contain '42'";

    println "\nTest 21: parse_statement_helper with assert";
    mut tokens21: list(Token) = lex(str("assert x > 0, \"x must be positive\";"));
    mut ctx21: ParserContext;
    ctx21.tokens = addr_of(tokens21);
    ctx21.pos = 0;
    ctx21.is_axec = false;
    mut stmt21: ASTNode = parse_statement_helper(addr_of(ctx21), addr_of(ctx21.current_scope));
    assert equals_c(stmt21.node_type, "Assert"), "Expected Assert node";
    assert str_len(stmt21.data.assert_node.condition) > 0, "Expected assert condition";
    assert str_len(stmt21.data.assert_node.message) > 0, "Expected assert message";

    println "\nTest 22: parse_statement_helper with unsafe block";
    mut tokens22: list(Token) = lex(str("unsafe { }"));
    mut ctx22: ParserContext;
    ctx22.tokens = addr_of(tokens22);
    ctx22.pos = 0;
    ctx22.is_axec = false;
    mut stmt22: ASTNode = parse_statement_helper(addr_of(ctx22), addr_of(ctx22.current_scope));
    assert equals_c(stmt22.node_type, "Unsafe"), "Expected Unsafe node";

    println "\nTest 23: parse_statement_helper with if-elif-else";
    mut tokens23: list(Token) = lex(str("if x > 0 { println x; } elif x < 0 { println x; } else { println x; }"));
    mut ctx23: ParserContext;
    ctx23.tokens = addr_of(tokens23);
    ctx23.pos = 0;
    ctx23.is_axec = false;
    mut stmt23: ASTNode = parse_statement_helper(addr_of(ctx23), addr_of(ctx23.current_scope));
    assert equals_c(stmt23.node_type, "If"), "Expected If node with elif and else";

    println "\nTest 24: parse_statement_helper with use statement";
    mut tokens24: list(Token) = lex(str("use std.io;"));
    mut ctx24: ParserContext;
    ctx24.tokens = addr_of(tokens24);
    ctx24.pos = 0;
    ctx24.is_axec = false;
    mut stmt24: ASTNode = parse_statement_helper(addr_of(ctx24), addr_of(ctx24.current_scope));
    assert equals_c(stmt24.node_type, "Use"), "Expected Use node";
    assert stmt24.data.use_node.import_all == true, "Expected import_all to be true";

    println "\nTest 25: parse_statement_helper with use selective imports";
    mut tokens25: list(Token) = lex(str("use std.maps (StringIntMap, StringStringMap);"));
    mut ctx25: ParserContext;
    ctx25.tokens = addr_of(tokens25);
    ctx25.pos = 0;
    ctx25.is_axec = false;
    mut stmt25: ASTNode = parse_statement_helper(addr_of(ctx25), addr_of(ctx25.current_scope));
    assert equals_c(stmt25.node_type, "Use"), "Expected Use node with selective imports";
    assert stmt25.data.use_node.import_all == false, "Expected import_all to be false";

    println "\nTest 26: parse_statement_helper with case";
    mut tokens26: list(Token) = lex(str("case 1 { println \"one\"; }"));
    mut ctx26: ParserContext;
    ctx26.tokens = addr_of(tokens26);
    ctx26.pos = 0;
    ctx26.is_axec = false;
    mut stmt26: ASTNode = parse_statement_helper(addr_of(ctx26), addr_of(ctx26.current_scope));
    assert equals_c(stmt26.node_type, "Case"), "Expected Case node";
    assert stmt26.data.case_node.is_default == false, "Expected non-default case";

    println "\nTest 27: parse_statement_helper with default";
    mut tokens27: list(Token) = lex(str("default { println \"other\"; }"));
    mut ctx27: ParserContext;
    ctx27.tokens = addr_of(tokens27);
    ctx27.pos = 0;
    ctx27.is_axec = false;
    mut stmt27: ASTNode = parse_statement_helper(addr_of(ctx27), addr_of(ctx27.current_scope));
    assert equals_c(stmt27.node_type, "Case"), "Expected Case node for default";
    assert stmt27.data.case_node.is_default == true, "Expected default case";

    println "\nTest 28: parse_statement_helper with member access assignment";
    mut tokens28: list(Token) = lex(str("obj.field = 42;"));
    mut ctx28: ParserContext;
    ctx28.tokens = addr_of(tokens28);
    ctx28.pos = 0;
    ctx28.is_axec = false;
    mut stmt28: ASTNode = parse_statement_helper(addr_of(ctx28), addr_of(ctx28.current_scope));
    assert equals_c(stmt28.node_type, "MemberAccess"), "Expected MemberAccess node";
    assert equals_c(stmt28.data.member_access.object_name, "obj"), "Expected object name 'obj'";
    assert equals_c(stmt28.data.member_access.member_name, "field"), "Expected member name 'field'";
    assert str_contains_c(stmt28.data.member_access.value, "42"), "Expected value to contain '42'";

    println "\nTest 29: parse_statement_helper with member access read";
    mut tokens29: list(Token) = lex(str("obj.field;"));
    mut ctx29: ParserContext;
    ctx29.tokens = addr_of(tokens29);
    ctx29.pos = 0;
    ctx29.is_axec = false;
    mut stmt29: ASTNode = parse_statement_helper(addr_of(ctx29), addr_of(ctx29.current_scope));
    assert equals_c(stmt29.node_type, "MemberAccess"), "Expected MemberAccess node";
    assert equals_c(stmt29.data.member_access.object_name, "obj"), "Expected object name 'obj'";
    assert equals_c(stmt29.data.member_access.member_name, "field"), "Expected member name 'field'";
    assert equals_c(stmt29.data.member_access.value, ""), "Expected empty value for read access";

    println "\nTest 30: parse_statement_helper with array access";
    mut tokens30: list(Token) = lex(str("arr[5];"));
    mut ctx30: ParserContext;
    ctx30.tokens = addr_of(tokens30);
    ctx30.pos = 0;
    ctx30.is_axec = false;
    mut stmt30: ASTNode = parse_statement_helper(addr_of(ctx30), addr_of(ctx30.current_scope));
    assert equals_c(stmt30.node_type, "ArrayAccess"), "Expected ArrayAccess node";
    assert equals_c(stmt30.data.array_access.array_name, "arr"), "Expected array name 'arr'";
    assert str_contains_c(stmt30.data.array_access.index, "5"), "Expected index to contain '5'";

    println "\nTest 31: parse_statement_helper with array assignment";
    mut tokens31: list(Token) = lex(str("arr[i] = 42;"));
    mut ctx31: ParserContext;
    ctx31.tokens = addr_of(tokens31);
    ctx31.pos = 0;
    ctx31.is_axec = false;
    mut stmt31: ASTNode = parse_statement_helper(addr_of(ctx31), addr_of(ctx31.current_scope));
    assert equals_c(stmt31.node_type, "ArrayAssign"), "Expected ArrayAssign node";
    assert equals_c(stmt31.data.array_assign.array_name, "arr"), "Expected array name 'arr'";
    assert str_contains_c(stmt31.data.array_assign.index, "i"), "Expected index to contain 'i'";
    assert str_contains_c(stmt31.data.array_assign.value, "42"), "Expected value to contain '42'";

    println "\nTest 32: parse_statement_helper with 2D array access";
    mut tokens32: list(Token) = lex(str("matrix[i][j];"));
    mut ctx32: ParserContext;
    ctx32.tokens = addr_of(tokens32);
    ctx32.pos = 0;
    ctx32.is_axec = false;
    mut stmt32: ASTNode = parse_statement_helper(addr_of(ctx32), addr_of(ctx32.current_scope));
    assert equals_c(stmt32.node_type, "ArrayAccess"), "Expected ArrayAccess node for 2D array";
    assert equals_c(stmt32.data.array_access.array_name, "matrix"), "Expected array name 'matrix'";
    assert str_contains_c(stmt32.data.array_access.index, "i"), "Expected first index to contain 'i'";
    assert str_contains_c(stmt32.data.array_access.index2, "j"), "Expected second index to contain 'j'";

    println "\nTest 33: parse_statement_helper with increment";
    mut tokens33: list(Token) = lex(str("x++;"));
    mut ctx33: ParserContext;
    ctx33.tokens = addr_of(tokens33);
    ctx33.pos = 0;
    ctx33.is_axec = false;
    mut stmt33: ASTNode = parse_statement_helper(addr_of(ctx33), addr_of(ctx33.current_scope));
    assert equals_c(stmt33.node_type, "IncDec"), "Expected IncDec node";
    assert equals_c(stmt33.data.inc_dec.variable, "x"), "Expected variable name 'x'";
    assert stmt33.data.inc_dec.is_increment == true, "Expected is_increment to be true";

    println "\nTest 34: parse_statement_helper with decrement";
    mut tokens34: list(Token) = lex(str("x--;"));
    mut ctx34: ParserContext;
    ctx34.tokens = addr_of(tokens34);
    ctx34.pos = 0;
    ctx34.is_axec = false;
    mut stmt34: ASTNode = parse_statement_helper(addr_of(ctx34), addr_of(ctx34.current_scope));
    assert equals_c(stmt34.node_type, "IncDec"), "Expected IncDec node";
    assert equals_c(stmt34.data.inc_dec.variable, "x"), "Expected variable name 'x'";
    assert stmt34.data.inc_dec.is_increment == false, "Expected is_increment to be false";

    println "\nTest 35: parse_statement_helper with member increment";
    mut tokens35: list(Token) = lex(str("obj.count++;"));
    mut ctx35: ParserContext;
    ctx35.tokens = addr_of(tokens35);
    ctx35.pos = 0;
    ctx35.is_axec = false;
    mut stmt35: ASTNode = parse_statement_helper(addr_of(ctx35), addr_of(ctx35.current_scope));
    assert equals_c(stmt35.node_type, "MemberIncDec"), "Expected MemberIncDec node";
    assert equals_c(stmt35.data.member_inc_dec.object_name, "obj"), "Expected object name 'obj'";
    assert equals_c(stmt35.data.member_inc_dec.member_name, "count"), "Expected member name 'count'";
    assert stmt35.data.member_inc_dec.is_increment == true, "Expected is_increment to be true";

    println "\nTest 36: parse_statement_helper with member decrement";
    mut tokens36: list(Token) = lex(str("obj.count--;"));
    mut ctx36: ParserContext;
    ctx36.tokens = addr_of(tokens36);
    ctx36.pos = 0;
    ctx36.is_axec = false;
    mut stmt36: ASTNode = parse_statement_helper(addr_of(ctx36), addr_of(ctx36.current_scope));
    assert equals_c(stmt36.node_type, "MemberIncDec"), "Expected MemberIncDec node";
    assert equals_c(stmt36.data.member_inc_dec.object_name, "obj"), "Expected object name 'obj'";
    assert equals_c(stmt36.data.member_inc_dec.member_name, "count"), "Expected member name 'count'";
    assert stmt36.data.member_inc_dec.is_increment == false, "Expected is_increment to be false";

    println "\nTest 37: A complete program parse";
    mut tokens37: list(Token) = lex(str(`use std.io;
        
        model Point {
            x: i32;
            y: i32;
        }
        
        enum Color {
            Red,
            Green,
            Blue
        }
        
        pub def main() {
            val p: Point = Point { x: 10, y: 20 };
            println p.x;
        }
    `));
    
    mut ctx37: ParserContext;

    ctx37.tokens = addr_of(tokens37);
    ctx37.pos = 0;
    ctx37.is_axec = false;

    mut stmt37: ASTNode = parse_statement_helper(addr_of(ctx37), addr_of(ctx37.current_scope));
    
    assert equals_c(stmt37.node_type, "Use"), "Expected Use node as first statement in program";
    assert equals_c(stmt37.data.use_node.module_name, "std.io"), "Expected module name 'std.io'";
}

// =============================================================================
// TDL: Missing features from parser.d that need to be ported to parser.axe
// =============================================================================
//
// HIGH PRIORITY (Core Language Features):
// ---------------------------------------
// 3. STRING INTERPOLATION
//    - Support string interpolation detection and std.string requirement checking
//
// MEDIUM PRIORITY (Statement Enhancements):
// -----------------------------------------
// 4. Enhanced EXTERN parameter parsing
//    - parser.d lines 1366-1459: Full parameter and return type parsing
//    - parser.axe lines 1863-1899: Simplified version that skips to semicolon
//    - parser.d stores full parameter list and return type in ExternNode
//    - parser.axe only captures function name
//
// LOW PRIORITY (Code Quality):
// ----------------------------
// 6. Better error messages with line/column info
//    - parser.d uses enforce() with detailed contextual messages
//    - parser.axe uses enforce_raw() with simple string messages
//    - Could add line/column from current token to errors
//
// 7. String interpolation validation
//    - parser.d checks for INTERPOLATED_STR token type
//    - Validates std.string is imported before allowing interpolation
//    - Checks for presence of {} or ${} in interpolated strings
//
// QUESTIONABLE/DEFERRED:
// ---------------------
// 8. Macro system completeness
//    - Both implementations have TokenType.MACRO handling
//    - parser.d has macro invocation in IDENTIFIER case (lines 1563+)
//    - Need to verify if parser.axe macro system is complete
//
// 9. UNSAFE block body parsing
//    - parser.d parses unsafe block body recursively (lines 1480-1523)
//    - parser.axe handles unsafe in parse_statement_helper (lines 1744+)
//    - Need to verify if approaches are equivalent
//
// COMPLETED:
// ---------
//  MAIN function parsing (def main() { ... })
//  OVERLOAD function parsing (type => function mappings)
//  SCOPE block parsing 
//  MODULE field type module path parsing (std.maps.StringIntMap, lexer.Token)
//  OPAQUE node type_names heap allocation fix
//  USE statement module path parsing (DOT and SLASH separators)
//  MODEL parsing with field types
//  ENUM parsing
//  DEF parsing
//  TEST parsing
//  PLATFORM block parsing
//  PARALLEL block parsing
//  SINGLE block parsing
//  RAW block parsing
//  Statement helper: BREAK, CONTINUE, ASSERT, RETURN, LOOP, FOR, IF, SWITCH
//  Variable declarations: MUT, VAL
//  Expression parsing with operators
//  Function calls with arguments
//  Increment/decrement operators (++/--)
//  Member access and member increment/decrement
//
// =============================================================================
// IMPLEMENTATION NOTES:
// =============================================================================
//
// For MAIN token:
// - Check if TokenType.MAIN exists in lexer.axe
// - Add case in parse_top_level after DEF handling
// - Create FunctionNode with name "main" and parse body until RBRACE
//
// For Enhanced EXTERN:
// - Parse parameter list properly: (name: type, name: type)
// - Parse optional return type after COLON
// - Store in ExternNode: function_name, params[], return_type
// - May require changes to structs.axe extern_node definition
//
// =============================================================================
