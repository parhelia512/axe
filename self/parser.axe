// Author: Navid Momtahen (C) 2025
// License: GPL-3.0
// 
// Handles the parsing process - converts tokens into an AST

use lexer (
    Token, 
    TokenType, lex
);

use structs (
    ASTNode
);

use std.string;
use std.io;
use std.maps;
use std.arena;
use std.errors;

mut g_type_aliases: StringStringMap;
mut g_imported_modules: StringBoolMap;
mut g_list_of_types: StringStringMap;

def initialize_all() {
    mut arena: Arena = Arena.create(1024 * 1024);
    g_type_aliases = deref(StringStringMap.create(ref_of(arena), 128));
    g_imported_modules = deref(StringBoolMap.create(ref_of(arena), 128));
    g_list_of_types = deref(StringStringMap.create(ref_of(arena), 128));
}

/// Parser context - holds state during parsing
model ParserContext {
    tokens: ref list(Token);
    pos: i32;
    is_axec: bool;
    check_entry_point: bool;
    current_module: string;
    current_scope: Scope;
}

/// Scope tracking for variable declarations
model Scope {
    variables: StringStringMap;
    parent: ref Scope;
}

/// Parse the tokens into an AST
pub def parse(tokens: ref list(Token), is_axec: bool, check_entry_point: bool, current_module: string): ASTNode {
    mut ctx: ParserContext;
    ctx.tokens = tokens;
    ctx.pos = 0;
    ctx.is_axec = is_axec;
    ctx.check_entry_point = check_entry_point;
    ctx.current_module = current_module;
    
    mut ast: ASTNode;
    ast.node_type = str("Program");
    
    // Clear global maps
    StringStringMap.clear(addr_of(g_type_aliases));
    StringBoolMap.clear(addr_of(g_imported_modules));
    StringStringMap.clear(addr_of(g_list_of_types));
    
    if str_len(current_module) > 0 {
        // g_imported_modules[current_module] = true
        println "Auto-imported current module: ";
        println current_module;
    }
    
    loop {
        if ctx.pos >= len(ctx.tokens) {
            break;
        }
        skip_whitespace(addr_of(ctx));        
        if ctx.pos >= len(ctx.tokens) {
            break;
        }
        parse_top_level(addr_of(ctx), addr_of(ast));
    }
    
    return ast;
}

/// Parse a top-level construct (use, def, model, enum, val, mut val, etc.)
def parse_top_level(ctx: ref ParserContext, ast: ref ASTNode) {
    if ctx.pos >= len(ctx.tokens) {
        return;
    }
    
    val token_type = ctx.tokens.data[ctx.pos].token_type;
    
    if token_type == TokenType.USE {
        ctx.pos++;
        skip_whitespace(ctx);
        
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            if ctx.tokens.data[ctx.pos].token_type == TokenType.SEMICOLON {
                ctx.pos++;
                break;
            }
            ctx.pos++;
        }
        return;
    }
    
    if token_type == TokenType.DEF {
        ctx.pos++;
        skip_whitespace(ctx);
        
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
            ctx.pos++;
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LPAREN {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LPAREN {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RPAREN {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.COLON {
            ctx.pos++;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    break;
                }
                ctx.pos++;
            }
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    if token_type == TokenType.MODEL {
        ctx.pos++;
        skip_whitespace(ctx);
        
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
            ctx.pos++;
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                
                skip_whitespace(ctx);
                
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    ctx.pos++;
                    break;
                }
                
                if ctx.tokens.data[ctx.pos].token_type == TokenType.PUB {
                    ctx.pos++;
                    skip_whitespace(ctx);
                }
                
                if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.DEF {
                    ctx.pos++;
                    skip_whitespace(ctx);
                    
                    if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
                        ctx.pos++;
                    }
                    
                    if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LPAREN {
                        ctx.pos++;
                        mut paren_depth: i32 = 1;
                        loop {
                            if ctx.pos >= len(ctx.tokens) {
                                break;
                            }
                            if ctx.tokens.data[ctx.pos].token_type == TokenType.LPAREN {
                                paren_depth = paren_depth + 1;
                            } elif ctx.tokens.data[ctx.pos].token_type == TokenType.RPAREN {
                                paren_depth = paren_depth - 1;
                                if paren_depth == 0 {
                                    ctx.pos++;
                                    break;
                                }
                            }
                            ctx.pos++;
                        }
                    }
                    
                    skip_whitespace(ctx);
                    
                    if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.COLON {
                        ctx.pos++;
                        val return_type: string = parse_type(ctx);
                    }
                    
                    skip_whitespace(ctx);
                    
                    if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                        ctx.pos++;
                        mut depth: i32 = 1;
                        loop {
                            if ctx.pos >= len(ctx.tokens) {
                                break;
                            }
                            if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                                depth = depth + 1;
                            } elif ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                                depth = depth - 1;
                                if depth == 0 {
                                    ctx.pos++;
                                    break;
                                }
                            }
                            ctx.pos++;
                        }
                    }
                } elif ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
                    val field_name: string = ctx.tokens.data[ctx.pos].value;
                    ctx.pos++;
                    
                    skip_whitespace(ctx);
                    
                    if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.COLON {
                        ctx.pos++;
                        skip_whitespace(ctx);
                        
                        // Parse base type
                        mut field_type: string = parse_type(ctx);
                        
                        loop {
                            skip_whitespace(ctx);
                            if ctx.pos >= len(ctx.tokens) {
                                break;
                            }
                            
                            if ctx.tokens.data[ctx.pos].token_type == TokenType.DOT {
                                field_type = concat(field_type, str("."));
                                ctx.pos++;
                                
                                skip_whitespace(ctx);
                                
                                if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
                                    field_type = concat(field_type, ctx.tokens.data[ctx.pos].value);
                                    ctx.pos++;
                                } else {
                                    break;
                                }
                            } elif ctx.tokens.data[ctx.pos].token_type == TokenType.SLASH {
                                field_type = concat(field_type, str("/"));
                                ctx.pos++;
                                
                                skip_whitespace(ctx);
                                
                                if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
                                    field_type = concat(field_type, ctx.tokens.data[ctx.pos].value);
                                    ctx.pos++;
                                } else {
                                    break;
                                }
                            } else {
                                break;
                            }
                        }
                        
                        skip_whitespace(ctx);
                        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.SEMICOLON {
                            ctx.pos++;
                        }
                    }
                } else {
                    ctx.pos++;
                }
            }
        }
        return;
    }
    
    if token_type == TokenType.ENUM {
        ctx.pos++;  // Skip 'enum'
        skip_whitespace(ctx);
        
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
            ctx.pos++;
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    if token_type == TokenType.MUT {
        ctx.pos++;
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.VAL {
            ctx.pos++;  // Skip 'val'
        }
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            if ctx.tokens.data[ctx.pos].token_type == TokenType.SEMICOLON {
                ctx.pos++;
                break;
            }
            ctx.pos++;
        }
        return;
    }
    
    if token_type == TokenType.VAL {
        ctx.pos++;  // Skip 'val'
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            if ctx.tokens.data[ctx.pos].token_type == TokenType.SEMICOLON {
                ctx.pos++;
                break;
            }
            ctx.pos++;
        }
        return;
    }
    
    if token_type == TokenType.TEST {
        ctx.pos++;  // Skip 'test'
        skip_whitespace(ctx);
        
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    if token_type == TokenType.PUB {
        ctx.pos++;  // Skip 'pub'
        skip_whitespace(ctx);
        parse_top_level(ctx, ast);
        return;
    }
    
    if token_type == TokenType.MACRO {
        ctx.pos++;  // Skip 'macro'
        skip_whitespace(ctx);
        
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
            ctx.pos++;
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LPAREN {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LPAREN {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RPAREN {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    if token_type == TokenType.OPAQUE {
        ctx.pos++;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            if ctx.tokens.data[ctx.pos].token_type == TokenType.SEMICOLON {
                ctx.pos++;
                break;
            }
            ctx.pos++;
        }
        return;
    }
    
    if token_type == TokenType.PLATFORM {
        ctx.pos++;
        skip_whitespace(ctx);
        
        if ctx.pos < len(ctx.tokens) {
            ctx.pos++;
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    // Unknown token type - skip it
    ctx.pos++;
}

/// Skip the whitespace and newline tokens
def skip_whitespace(ctx: ref ParserContext) {
    loop {
        if ctx.pos >= len(ctx.tokens) {
            break;
        }
        
        val token_type = ctx.tokens.data[ctx.pos].token_type;
        
        if token_type == TokenType.WHITESPACE or token_type == TokenType.NEWLINE {
            ctx.pos++;
        } else {
            break;
        }
    }
}

/// Peek at current token without advancing
def peek(ctx: ref ParserContext): Token {
    if ctx.pos < len(ctx.tokens) {
        return ctx.tokens.data[ctx.pos];
    }
    
    mut empty: Token;
    empty.token_type = TokenType.IDENTIFIER;
    empty.value = str("");
    empty.line = 0;
    empty.column = 0;
    return empty;
}

/// Consume current token and advance
def consume(ctx: ref ParserContext): Token {
    val token: Token = peek(ctx);
    ctx.pos = ctx.pos + 1;
    return token;
}

/// Check if current token matches expected type
def expect(ctx: ref ParserContext, expected_type: i32): bool {
    skip_whitespace(ctx);
    val token: Token = peek(ctx);
    return token.token_type == expected_type;
}

/// Parse a type specification (e.g., "i32", "ref string", "list(Token)")
def parse_type(ctx: ref ParserContext): string {
    skip_whitespace(ctx);
    
    if ctx.pos >= len(ctx.tokens) {
        enforce_raw(false, "Expected type but reached end of tokens");
        return str("");
    }
    
    mut ref_prefix: string = str("");
    
    loop {
        val token: Token = peek(ctx);
        if token.token_type == TokenType.REF {
            ref_prefix = concat_c(ref_prefix, "ref ");
            consume(ctx);
            skip_whitespace(ctx);
        } else {
            break;
        }
    }
    
    skip_whitespace(ctx);
    mut type_name: string = str("");
    val current_token: Token = peek(ctx);
    
    if current_token.token_type == TokenType.MODEL {
        consume(ctx);
        return concat_c(ref_prefix, "model");
    }
    
    if current_token.token_type == TokenType.IDENTIFIER {
        type_name = current_token.value;
        consume(ctx);
        
        // Handle list(ElementType) syntax
        if equals_c(type_name, "list") {
            skip_whitespace(ctx);
            
            if !expect(ctx, TokenType.LPAREN) {
                enforce_raw(false, "ERROR: Expected '(' after 'list'");
                return str("");
            }
            consume(ctx);
            
            skip_whitespace(ctx);
            val elem_token: Token = consume(ctx);
            val element_type: string = elem_token.value;
            
            skip_whitespace(ctx);
            if !expect(ctx, TokenType.RPAREN) {
                enforce_raw(false, "ERROR: Expected ')' after list element type");
                return str("");
            }
            consume(ctx);
            type_name = concat(element_type, str("[999]"));
        }

        loop {
            if expect(ctx, TokenType.LBRACKET) {
                consume(ctx);
                type_name = concat(type_name, str("["));
                
                loop {
                    val tok: Token = peek(ctx);
                    if tok.token_type == TokenType.RBRACKET {
                        break;
                    }
                    type_name = concat(type_name, tok.value);
                    consume(ctx);
                }
                
                if expect(ctx, TokenType.RBRACKET) {
                    consume(ctx);
                    type_name = concat(type_name, str("]"));
                }
            } else {
                break;
            }
        }
        
        loop {
            val tok: Token = peek(ctx);
            if tok.token_type == TokenType.OPERATOR and equals_c(tok.value, "*") {
                consume(ctx);
                type_name = concat(type_name, str("*"));
            } else {
                break;
            }
        }
    } else {
        enforce_raw(false, "ERROR: Invalid type specification");
        return str("");
    }
    
    // TODO: Check type aliases
    // if type_name in g_type_aliases {
    //     type_name = g_type_aliases[type_name]
    // }
    
    return concat(ref_prefix, type_name);
}

/// Parse ref depth (e.g., "ref ref int" returns 2)
def parse_ref_depth(ctx: ref ParserContext): i32 {
    mut depth: i32 = 0;
    
    loop {
        skip_whitespace(ctx);
        
        if ctx.pos >= len(ctx.tokens) {
            break;
        }
        
        val token: Token = peek(ctx);
        if token.token_type == TokenType.REF {
            depth = depth + 1;
            consume(ctx);
        } else {
            break;
        }
    }
    
    return depth;
}

/// Parse function definition
def parse_function(ctx: ref ParserContext): ASTNode {
    mut func: ASTNode;
    func.node_type = str("Function");
    
    skip_whitespace(ctx);
    if ctx.pos >= len(ctx.tokens) or ctx.tokens.data[ctx.pos].token_type != TokenType.IDENTIFIER {
        enforce_raw(false, "ERROR: Expected function name after 'def'");
        return func;
    }
    
    val func_name: string = ctx.tokens.data[ctx.pos].value;
    ctx.pos++;
    
    skip_whitespace(ctx);
    if !expect(ctx, TokenType.LPAREN) {
        enforce_raw(false, "ERROR: Expected '(' after function name");
        return func;
    }
    consume(ctx);
    
    mut depth: i32 = 1;
    loop {
        if ctx.pos >= len(ctx.tokens) {
            break;
        }
        
        val current_tok: Token = ctx.tokens.data[ctx.pos];
        if current_tok.token_type == TokenType.LPAREN {
            depth = depth + 1;
        } elif current_tok.token_type == TokenType.RPAREN {
            depth = depth - 1;
            if depth == 0 {
                ctx.pos++;
                break;
            }
        }
        ctx.pos++;
    }
    
    skip_whitespace(ctx);
    if expect(ctx, TokenType.COLON) {
        consume(ctx);
        val return_type: string = parse_type(ctx);
    }
    
    skip_whitespace(ctx);
    if !expect(ctx, TokenType.LBRACE) {
        enforce_raw(false, "ERROR: Expected '{' after function declaration");
        return func;
    }
    consume(ctx);
    
    depth = 1;
    loop {
        if ctx.pos >= len(ctx.tokens) {
            break;
        }
        
        val body_tok: Token = ctx.tokens.data[ctx.pos];
        if body_tok.token_type == TokenType.LBRACE {
            depth = depth + 1;
        } elif body_tok.token_type == TokenType.RBRACE {
            depth = depth - 1;
            if depth == 0 {
                ctx.pos++;
                break;
            }
        }
        ctx.pos++;
    }
    
    return func;
}

/// Parse a single statement (helper for parsing function bodies, loops, etc.)
///
/// Returns an ASTNode for the statement, or null node for whitespace/newlines
def parse_statement_helper(ctx: ref ParserContext): ASTNode {
    mut node: ASTNode;
    node.node_type = str("Empty");
    
    if ctx.pos >= len(ctx.tokens) {
        return node;
    }
    
    val token: Token = peek(ctx);
    val token_type: i32 = token.token_type;
    
    if token_type == TokenType.WHITESPACE or token_type == TokenType.NEWLINE {
        consume(ctx);
        return node;
    }
    
    // Handle BREAK
    if token_type == TokenType.BREAK {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.SEMICOLON) {
            enforce_raw(false, "ERROR: Expected ';' after break");
            return node;
        }
        consume(ctx);
        
        node.node_type = str("Break");
        return node;
    }
    
    // Handle CONTINUE
    if token_type == TokenType.CONTINUE {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.SEMICOLON) {
            enforce_raw(false, "ERROR: Expected ';' after continue");
            return node;
        }
        consume(ctx);
        
        node.node_type = str("Continue");
        return node;
    }
    
    // Handle ASSERT
    if token_type == TokenType.ASSERT {
        consume(ctx);
        skip_whitespace(ctx);
        
        mut has_parens: bool = false;
        if expect(ctx, TokenType.LPAREN) {
            has_parens = true;
            consume(ctx);
        }
        
        mut condition: string = str("");
        mut paren_depth: i32 = 0;
        
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            
            if t.token_type == TokenType.LPAREN {
                paren_depth = paren_depth + 1;
                condition = concat(condition, t.value);
                condition = concat(condition, str(" "));
            } elif t.token_type == TokenType.RPAREN {
                if paren_depth == 0 and has_parens {
                    break;
                }
                paren_depth = paren_depth - 1;
                condition = concat(condition, t.value);
                condition = concat(condition, str(" "));
            } elif t.token_type == TokenType.COMMA and paren_depth == 0 {
                break;
            } elif t.token_type != TokenType.WHITESPACE and t.token_type != TokenType.NEWLINE {
                if t.token_type == TokenType.STR {
                    condition = concat(condition, str("\""));
                    condition = concat(condition, t.value);
                    condition = concat(condition, str("\" "));
                } elif t.token_type == TokenType.CHAR {
                    condition = concat(condition, str("'"));
                    condition = concat(condition, t.value);
                    condition = concat(condition, str("' "));
                } else {
                    condition = concat(condition, t.value);
                    condition = concat(condition, str(" "));
                }
            }
            consume(ctx);
        }
        
        if !expect(ctx, TokenType.COMMA) {
            enforce_raw(false, "ERROR: Expected ',' after assert condition");
            return node;
        }
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.STR) {
            enforce_raw(false, "ERROR: Expected string message after comma in assert");
            return node;
        }
        val message_token: Token = consume(ctx);
        val message: string = message_token.value;
        skip_whitespace(ctx);
        
        if has_parens {
            if !expect(ctx, TokenType.RPAREN) {
                enforce_raw(false, "ERROR: Expected ')' after assert message");
                return node;
            }
            consume(ctx);
            skip_whitespace(ctx);
        }
        
        if !expect(ctx, TokenType.SEMICOLON) {
            enforce_raw(false, "ERROR: Expected ';' after assert statement");
            return node;
        }
        consume(ctx);
        
        node.node_type = str("Assert");
        node.data.assert_node.condition = condition;
        node.data.assert_node.message = message;
        return node;
    }
    
    // Handle RETURN
    if token_type == TokenType.RETURN {
        consume(ctx);
        skip_whitespace(ctx);
        
        mut expr: string = str("");
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.SEMICOLON {
                break;
            }
            if t.token_type == TokenType.STR {
                expr = concat(expr, str("\""));
                expr = concat(expr, t.value);
                expr = concat(expr, str("\" "));
            } elif t.token_type == TokenType.WHITESPACE or t.token_type == TokenType.NEWLINE {
                // Skip whitespace
            } else {
                expr = concat(expr, t.value);
                expr = concat(expr, str(" "));
            }
            consume(ctx);
        }
        
        if !expect(ctx, TokenType.SEMICOLON) {
            enforce_raw(false, "ERROR: Expected ';' after return");
            return node;
        }
        consume(ctx);
        
        node.node_type = str("Return");
        node.data.return_node.expression = expr;
        return node;
    }
    
    // Handle LOOP
    if token_type == TokenType.LOOP {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after loop");
            return node;
        }
        consume(ctx);
        
        // Skip loop body for now (just balance braces)
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Loop");
        return node;
    }
    
    // Handle SWITCH
    if token_type == TokenType.SWITCH {
        consume(ctx);
        skip_whitespace(ctx);
        
        mut switch_expr: string = str("");
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                break;
            }
            if t.token_type != TokenType.WHITESPACE and t.token_type != TokenType.NEWLINE {
                switch_expr = concat(switch_expr, t.value);
                switch_expr = concat(switch_expr, str(" "));
            }
            consume(ctx);
        }
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after switch expression");
            return node;
        }
        consume(ctx);
        
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Switch");
        return node;
    }
    
    // Handle IF
    if token_type == TokenType.IF {
        consume(ctx);
        skip_whitespace(ctx);
        
        mut condition: string = str("");
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                break;
            }
            if t.token_type != TokenType.WHITESPACE and t.token_type != TokenType.NEWLINE {
                condition = concat(condition, t.value);
                condition = concat(condition, str(" "));
            }
            consume(ctx);
        }
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after if condition");
            return node;
        }
        consume(ctx);
        
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        // Handle elif clauses
        skip_whitespace(ctx);
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type != TokenType.ELIF {
                break;
            }
            
            consume(ctx);
            skip_whitespace(ctx);
            
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val elif_t: Token = peek(ctx);
                if elif_t.token_type == TokenType.LBRACE {
                    break;
                }
                consume(ctx);
            }
            
            if !expect(ctx, TokenType.LBRACE) {
                enforce_raw(false, "ERROR: Expected '{' after elif condition");
                return node;
            }
            consume(ctx);
            
            depth = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val elif_body_t: Token = peek(ctx);
                if elif_body_t.token_type == TokenType.LBRACE {
                    depth = depth + 1;
                } elif elif_body_t.token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        consume(ctx);
                        break;
                    }
                }
                consume(ctx);
            }
            
            skip_whitespace(ctx);
        }
        
        // Handle else clause
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) {
            val t: Token = peek(ctx);
            if t.token_type == TokenType.ELSE {
                consume(ctx);
                skip_whitespace(ctx);
                
                if !expect(ctx, TokenType.LBRACE) {
                    enforce_raw(false, "ERROR: Expected '{' after else");
                    return node;
                }
                consume(ctx);
                
                depth = 1;
                loop {
                    if ctx.pos >= len(ctx.tokens) {
                        break;
                    }
                    val else_t: Token = peek(ctx);
                    if else_t.token_type == TokenType.LBRACE {
                        depth = depth + 1;
                    } elif else_t.token_type == TokenType.RBRACE {
                        depth = depth - 1;
                        if depth == 0 {
                            consume(ctx);
                            break;
                        }
                    }
                    consume(ctx);
                }
            }
        }
        
        node.node_type = str("If");
        node.data.if_node.condition = condition;
        return node;
    }
    
    // Handle FOR
    if token_type == TokenType.FOR {
        consume(ctx);
        skip_whitespace(ctx);
        
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                break;
            }
            consume(ctx);
        }
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after for header");
            return node;
        }
        consume(ctx);
        
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("For");
        return node;
    }
    
    // Handle VAL and MUT VAL (variable declarations)
    if token_type == TokenType.VAL {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.IDENTIFIER) {
            enforce_raw(false, "ERROR: Expected identifier after 'val'");
            return node;
        }
        val var_name: Token = consume(ctx);
        skip_whitespace(ctx);
        
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.SEMICOLON {
                consume(ctx);
                break;
            }
            consume(ctx);
        }
        
        node.node_type = str("Declaration");
        return node;
    }
    
    if token_type == TokenType.MUT {
        consume(ctx); // Skip 'mut'
        skip_whitespace(ctx);
        
        if expect(ctx, TokenType.VAL) {
            consume(ctx);
            skip_whitespace(ctx);
        }
        
        if !expect(ctx, TokenType.IDENTIFIER) {
            enforce_raw(false, "ERROR: Expected identifier after 'mut'");
            return node;
        }
        val var_name: Token = consume(ctx);
        skip_whitespace(ctx);
        
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.SEMICOLON {
                consume(ctx);
                break;
            }
            consume(ctx);
        }
        
        node.node_type = str("Declaration");
        return node;
    }
    
    // Handle IDENTIFIER (function calls, assignments, etc.)
    if token_type == TokenType.IDENTIFIER {
        val ident_token: Token = consume(ctx);
        val ident_name: string = ident_token.value;
        skip_whitespace(ctx);
        
        if ctx.pos >= len(ctx.tokens) {
            return node;
        }
        
        val next_token: Token = peek(ctx);
        
        if next_token.token_type == TokenType.LPAREN {
            consume(ctx);            
            mut paren_depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.LPAREN {
                    paren_depth = paren_depth + 1;
                } elif t.token_type == TokenType.RPAREN {
                    paren_depth = paren_depth - 1;
                    if paren_depth == 0 {
                        consume(ctx);
                        break;
                    }
                }
                consume(ctx);
            }
            
            skip_whitespace(ctx);
            
            if expect(ctx, TokenType.SEMICOLON) {
                consume(ctx);
            }
            
            node.node_type = str("FunctionCall");
            return node;
        }
        
        if next_token.token_type == TokenType.LBRACKET {
            // Array access: array[index] or array[index] = value or array[i][j]
            consume(ctx); // Skip '['
            skip_whitespace(ctx);
            
            mut index_expr: string = str("");
            mut bracket_depth: i32 = 0;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.LBRACKET {
                    bracket_depth = bracket_depth + 1;
                    index_expr = concat(index_expr, t.value);
                    index_expr = concat(index_expr, str(" "));
                } elif t.token_type == TokenType.RBRACKET {
                    if bracket_depth == 0 {
                        break;
                    }
                    bracket_depth = bracket_depth - 1;
                    index_expr = concat(index_expr, t.value);
                    index_expr = concat(index_expr, str(" "));
                } elif t.token_type != TokenType.WHITESPACE and t.token_type != TokenType.NEWLINE {
                    index_expr = concat(index_expr, t.value);
                    index_expr = concat(index_expr, str(" "));
                }
                consume(ctx);
            }
            
            if !expect(ctx, TokenType.RBRACKET) {
                enforce_raw(false, "ERROR: Expected ']' after array index");
                return node;
            }
            consume(ctx);
            skip_whitespace(ctx);
            
            mut index2_expr: string = str("");
            if expect(ctx, TokenType.LBRACKET) {
                consume(ctx); // Skip '['
                skip_whitespace(ctx);
                
                bracket_depth = 0;
                loop {
                    if ctx.pos >= len(ctx.tokens) {
                        break;
                    }
                    val t: Token = peek(ctx);
                    if t.token_type == TokenType.LBRACKET {
                        bracket_depth = bracket_depth + 1;
                        index2_expr = concat(index2_expr, t.value);
                        index2_expr = concat(index2_expr, str(" "));
                    } elif t.token_type == TokenType.RBRACKET {
                        if bracket_depth == 0 {
                            break;
                        }
                        bracket_depth = bracket_depth - 1;
                        index2_expr = concat(index2_expr, t.value);
                        index2_expr = concat(index2_expr, str(" "));
                    } elif t.token_type != TokenType.WHITESPACE and t.token_type != TokenType.NEWLINE {
                        index2_expr = concat(index2_expr, t.value);
                        index2_expr = concat(index2_expr, str(" "));
                    }
                    consume(ctx);
                }
                
                if !expect(ctx, TokenType.RBRACKET) {
                    enforce_raw(false, "ERROR: Expected ']' after second array index");
                    return node;
                }
                consume(ctx);
                skip_whitespace(ctx);
            }
            
            // Check if this is array assignment: array[index] = value
            if expect(ctx, TokenType.OPERATOR) {
                val op_token: Token = peek(ctx);
                if equals_c(op_token.value, "=") {
                    consume(ctx); // Skip '='
                    skip_whitespace(ctx);
                    
                    mut value_expr: string = str("");
                    loop {
                        if ctx.pos >= len(ctx.tokens) {
                            break;
                        }
                        val t: Token = peek(ctx);
                        if t.token_type == TokenType.SEMICOLON {
                            consume(ctx);
                            break;
                        }
                        if t.token_type == TokenType.STR {
                            value_expr = concat(value_expr, str("\""));
                            value_expr = concat(value_expr, t.value);
                            value_expr = concat(value_expr, str("\" "));
                        } elif t.token_type == TokenType.WHITESPACE or t.token_type == TokenType.NEWLINE {
                        } else {
                            value_expr = concat(value_expr, t.value);
                            value_expr = concat(value_expr, str(" "));
                        }
                        consume(ctx);
                    }
                    
                    node.node_type = str("ArrayAssign");
                    node.data.array_assign.array_name = ident_name;
                    node.data.array_assign.index = index_expr;
                    node.data.array_assign.index2 = index2_expr;
                    node.data.array_assign.value = value_expr;
                    return node;
                }
            }
            
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.SEMICOLON {
                    consume(ctx);
                    break;
                }
                consume(ctx);
            }
            
            node.node_type = str("ArrayAccess");
            node.data.array_access.array_name = ident_name;
            node.data.array_access.index = index_expr;
            node.data.array_access.index2 = index2_expr;
            return node;
        }
        
        if next_token.token_type == TokenType.DOT {
            // Member access: object.member or object.member = value
            consume(ctx); // Skip '.'
            skip_whitespace(ctx);
            
            if !expect(ctx, TokenType.IDENTIFIER) {
                enforce_raw(false, "ERROR: Expected member name after '.'");
                return node;
            }
            val member_token: Token = consume(ctx);
            val member_name: string = member_token.value;
            skip_whitespace(ctx);
            
            if expect(ctx, TokenType.OPERATOR) {
                val op_token: Token = peek(ctx);
                if equals_c(op_token.value, "=") {
                    consume(ctx); // Skip '='
                    skip_whitespace(ctx);
                    
                    // Collect the value expression until semicolon
                    mut value_expr: string = str("");
                    loop {
                        if ctx.pos >= len(ctx.tokens) {
                            break;
                        }
                        val t: Token = peek(ctx);
                        if t.token_type == TokenType.SEMICOLON {
                            consume(ctx);
                            break;
                        }
                        if t.token_type == TokenType.STR {
                            value_expr = concat(value_expr, str("\""));
                            value_expr = concat(value_expr, t.value);
                            value_expr = concat(value_expr, str("\" "));
                        } elif t.token_type == TokenType.WHITESPACE or t.token_type == TokenType.NEWLINE {
                            // Skip whitespace in value
                        } else {
                            value_expr = concat(value_expr, t.value);
                            value_expr = concat(value_expr, str(" "));
                        }
                        consume(ctx);
                    }
                    
                    node.node_type = str("MemberAccess");
                    node.data.member_access.object_name = ident_name;
                    node.data.member_access.member_name = member_name;
                    node.data.member_access.value = value_expr;
                    return node;
                }
            }
            
            // Check for: member increment/decrement, so obj.field++ or obj.field--
            if expect(ctx, TokenType.INCREMENT) or expect(ctx, TokenType.DECREMENT) {
                val inc_dec_token: Token = peek(ctx);
                val is_inc: bool = inc_dec_token.token_type == TokenType.INCREMENT;
                consume(ctx);
                skip_whitespace(ctx);
                
                if !expect(ctx, TokenType.SEMICOLON) {
                    enforce_raw(false, "ERROR: Expected ';' after member increment/decrement");
                    return node;
                }
                consume(ctx);
                
                node.node_type = str("MemberIncDec");
                node.data.member_inc_dec.object_name = ident_name;
                node.data.member_inc_dec.member_name = member_name;
                node.data.member_inc_dec.is_increment = is_inc;
                return node;
            }
            
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.SEMICOLON {
                    consume(ctx);
                    break;
                }
                consume(ctx);
            }
            
            node.node_type = str("MemberAccess");
            node.data.member_access.object_name = ident_name;
            node.data.member_access.member_name = member_name;
            node.data.member_access.value = str("");
            return node;
        }
        
        if next_token.token_type == TokenType.OPERATOR and equals_c(next_token.value, "=") {
            consume(ctx); // Skip '='
            skip_whitespace(ctx);
            
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.SEMICOLON {
                    consume(ctx);
                    break;
                }
                consume(ctx);
            }
            
            node.node_type = str("Assignment");
            return node;
        }
        
        // Handle: INCREMENT and DECREMENT: variable++ or variable--
        if next_token.token_type == TokenType.INCREMENT or next_token.token_type == TokenType.DECREMENT {
            val is_inc: bool = next_token.token_type == TokenType.INCREMENT;
            consume(ctx);
            skip_whitespace(ctx);
            
            if !expect(ctx, TokenType.SEMICOLON) {
                enforce_raw(false, "ERROR: Expected ';' after increment/decrement");
                return node;
            }
            consume(ctx);
            
            node.node_type = str("IncDec");
            node.data.inc_dec.variable = ident_name;
            node.data.inc_dec.is_increment = is_inc;
            return node;
        }
        
        // Function call without parentheses (Axe syntax sugar): e.g. println "hello"
        // Consume until semicolon
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.SEMICOLON {
                consume(ctx);
                break;
            }
            consume(ctx);
        }
        
        node.node_type = str("FunctionCall");
        return node;
    }
    
    // Handle PLATFORM
    if token_type == TokenType.PLATFORM {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.WINDOWS) and !expect(ctx, TokenType.POSIX) {
            enforce_raw(false, "ERROR: Expected 'windows' or 'posix' after 'platform'");
            return node;
        }
        val platform_token: Token = consume(ctx);
        val platform_name: string = platform_token.value;
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after platform name");
            return node;
        }
        consume(ctx);
        
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Platform");
        node.data.platform_node.platform_name = platform_name;
        return node;
    }
    
    // Handle PARALLEL
    if token_type == TokenType.PARALLEL {
        consume(ctx);
        skip_whitespace(ctx);
        
        if expect(ctx, TokenType.FOR) {
            consume(ctx);
            skip_whitespace(ctx);
            
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.LBRACE {
                    break;
                }
                consume(ctx);
            }
            
            if !expect(ctx, TokenType.LBRACE) {
                enforce_raw(false, "ERROR: Expected '{' after parallel for header");
                return node;
            }
            consume(ctx);
            
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                val t: Token = peek(ctx);
                if t.token_type == TokenType.LBRACE {
                    depth = depth + 1;
                } elif t.token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        consume(ctx);
                        break;
                    }
                }
                consume(ctx);
            }
            
            node.node_type = str("ParallelFor");
            return node;
        }
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after 'parallel'");
            return node;
        }
        consume(ctx);
        
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Parallel");
        return node;
    }
    
    // Handle SINGLE
    if token_type == TokenType.SINGLE {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after 'single'");
            return node;
        }
        consume(ctx);
        
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Single");
        return node;
    }
    
    if token_type == TokenType.UNSAFE {
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after 'unsafe'");
            return node;
        }
        consume(ctx);
        
        // Skip body (in future, parse statements recursively)
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Unsafe");
        return node;
    }
    
    // Handle RAW (only in .axec files)
    if token_type == TokenType.RAW {
        if !ctx.is_axec {
            enforce_raw(false, "ERROR: Raw C blocks are only allowed in .axec files");
            return node;
        }
        
        consume(ctx); // Skip 'raw'
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after 'raw'");
            return node;
        }
        consume(ctx);
        
        // Collect raw code until closing brace
        mut raw_code: string = str("");
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.RBRACE {
                consume(ctx);
                break;
            }
            raw_code = concat(raw_code, t.value);
            consume(ctx);
        }
        
        node.node_type = str("RawC");
        node.data.raw_c.code = raw_code;
        return node;
    }
    
    // Handle OPAQUE (only in .axec files)
    if token_type == TokenType.OPAQUE {
        consume(ctx); // Skip 'opaque'
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after 'opaque'");
            return node;
        }
        consume(ctx);
        
        // Collect opaque type names
        mut type_names: list(string);
        loop {
            skip_whitespace(ctx);
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.RBRACE {
                consume(ctx);
                break;
            }
            if t.token_type == TokenType.IDENTIFIER {
                append(type_names, t.value);
                consume(ctx);
            } elif t.token_type == TokenType.SEMICOLON or t.token_type == TokenType.COMMA {
                consume(ctx);
            } else {
                consume(ctx);
            }
        }
        
        skip_whitespace(ctx);
        
        node.node_type = str("Opaque");
        // TODO: Fix.
        // For now, just mark it as Opaque - proper list assignment in unions needs compiler support
        // node.data.opaque_node.type_names = type_names;
        return node;
    }
    
    // Handle EXTERN (only in .axec files)
    if token_type == TokenType.EXTERN {
        consume(ctx); // Skip 'extern'
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.DEF) {
            enforce_raw(false, "ERROR: Expected 'def' after 'extern'");
            return node;
        }
        consume(ctx);
        skip_whitespace(ctx);
        
        // Get function name
        if !expect(ctx, TokenType.IDENTIFIER) {
            enforce_raw(false, "ERROR: Expected function name after 'extern def'");
            return node;
        }
        val func_name_token: Token = consume(ctx);
        val func_name: string = func_name_token.value;
        skip_whitespace(ctx);
        
        // Skip parameters and return type until semicolon
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.SEMICOLON {
                consume(ctx);
                break;
            }
            consume(ctx);
        }
        
        node.node_type = str("Extern");
        node.data.extern_node.function_name = func_name;
        return node;
    }
    
    if token_type == TokenType.USE {
        consume(ctx); // Skip 'use'
        skip_whitespace(ctx);
        
        if expect(ctx, TokenType.EXTERNAL) {
            consume(ctx);
            skip_whitespace(ctx);
            
            if !expect(ctx, TokenType.LPAREN) {
                enforce_raw(false, "ERROR: Expected '(' after 'use external'");
                return node;
            }
            consume(ctx);
            
            if !expect(ctx, TokenType.STR) {
                enforce_raw(false, "ERROR: Expected string literal for header file");
                return node;
            }
            val header_token: Token = consume(ctx);
            val header_file: string = header_token.value;
            
            if !expect(ctx, TokenType.RPAREN) {
                enforce_raw(false, "ERROR: Expected ')' after header file");
                return node;
            }
            consume(ctx);
            skip_whitespace(ctx);
            
            if !expect(ctx, TokenType.SEMICOLON) {
                enforce_raw(false, "ERROR: Expected ';' after external import");
                return node;
            }
            consume(ctx);
            
            node.node_type = str("ExternalImport");
            node.data.external_import.header_file = header_file;
            return node;
        }
        
        mut module_name: string = str("");
        
        loop {
            if expect(ctx, TokenType.DOT) {
                val dot_tok: Token = peek(ctx);
                consume(ctx);
                
                if expect(ctx, TokenType.DOT) {
                    consume(ctx);
                    if expect(ctx, TokenType.SLASH) {
                        consume(ctx);
                        module_name = concat(module_name, str("../"));
                        continue;
                    }
                } elif expect(ctx, TokenType.SLASH) {
                    consume(ctx);
                    module_name = concat(module_name, str("./"));
                    continue;
                }
            }
            break;
        }
        
        // Parse module path (e.g., std.io or std/maps)
        if !expect(ctx, TokenType.IDENTIFIER) {
            enforce_raw(false, "ERROR: Expected module name after 'use'");
            return node;
        }
        val first_ident: Token = consume(ctx);
        module_name = concat(module_name, first_ident.value);
        
        loop {
            skip_whitespace(ctx);
            if expect(ctx, TokenType.DOT) {
                consume(ctx);
                module_name = concat(module_name, str("."));
                
                if !expect(ctx, TokenType.IDENTIFIER) {
                    enforce_raw(false, "ERROR: Expected identifier after '.' in module path");
                    return node;
                }
                val ident: Token = consume(ctx);
                module_name = concat(module_name, ident.value);
            } elif expect(ctx, TokenType.SLASH) {
                consume(ctx);
                module_name = concat(module_name, str("/"));
                
                if !expect(ctx, TokenType.IDENTIFIER) {
                    enforce_raw(false, "ERROR: Expected identifier after '/' in module path");
                    return node;
                }
                val ident: Token = consume(ctx);
                module_name = concat(module_name, ident.value);
            } else {
                break;
            }
        }
        
        skip_whitespace(ctx);
        
        // Check for import all syntax: use module;
        if expect(ctx, TokenType.SEMICOLON) {
            consume(ctx);
            node.node_type = str("Use");
            node.data.use_node.module_name = module_name;
            node.data.use_node.import_all = true;
            return node;
        }
        
        // Parse selective imports: use module (item1, item2);
        if !expect(ctx, TokenType.LPAREN) {
            enforce_raw(false, "ERROR: Expected '(' or ';' after module name");
            return node;
        }
        consume(ctx);
        
        mut imports: list(string);
        loop {
            skip_whitespace(ctx);
            if expect(ctx, TokenType.RPAREN) {
                break;
            }
            
            if expect(ctx, TokenType.IDENTIFIER) {
                val import_token: Token = consume(ctx);
                append(imports, import_token.value);
            } elif expect(ctx, TokenType.COMMA) {
                consume(ctx);
            } else {
                enforce_raw(false, "ERROR: Expected identifier or ',' in use statement");
                return node;
            }
        }
        
        if !expect(ctx, TokenType.RPAREN) {
            enforce_raw(false, "ERROR: Expected ')' after imports");
            return node;
        }
        consume(ctx);
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.SEMICOLON) {
            enforce_raw(false, "ERROR: Expected ';' after use statement");
            return node;
        }
        consume(ctx);
        
        node.node_type = str("Use");
        node.data.use_node.module_name = module_name;
        
        // Heap-allocate the imports list so it persists after function returns
        // The list struct contains data inline, so we just copy the whole struct
        unsafe {
            val list_size: usize = C.sizeof(list(string));
            mut heap_list: ref list(string) = cast[ref list(string)](C.malloc(list_size));
            if heap_list != nil {
                C.memcpy(heap_list, addr_of(imports), list_size);
                node.data.use_node.imports = heap_list;
            }
        }
        
        node.data.use_node.import_all = false;
        return node;
    }
    
    // Handle CASE (within switch statements)
    if token_type == TokenType.CASE {
        println "[DEBUG] Parsing CASE statement";
        consume(ctx); // Skip 'case'
        println "[DEBUG] Consumed 'case' token";
        skip_whitespace(ctx);
        println "[DEBUG] Skipped whitespace after 'case'";
        
        // Collect case value until '{'
        mut case_value: string = str("");
        println "[DEBUG] Starting to collect case value";
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                break;
            }
            if t.token_type != TokenType.WHITESPACE and t.token_type != TokenType.NEWLINE {
                case_value = concat(case_value, t.value);
                case_value = concat(case_value, str(" "));
            }
            consume(ctx);
        }
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after case value");
            return node;
        }
        consume(ctx);
        
        // Skip case body
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Case");
        node.data.case_node.value = case_value;
        node.data.case_node.is_default = false;
        return node;
    }
    
    // Handle DEFAULT (within switch statements)
    if token_type == TokenType.DEFAULT {
        consume(ctx); // Skip 'default'
        skip_whitespace(ctx);
        
        if !expect(ctx, TokenType.LBRACE) {
            enforce_raw(false, "ERROR: Expected '{' after default");
            return node;
        }
        consume(ctx);
        
        // Skip default body
        mut depth: i32 = 1;
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            val t: Token = peek(ctx);
            if t.token_type == TokenType.LBRACE {
                depth = depth + 1;
            } elif t.token_type == TokenType.RBRACE {
                depth = depth - 1;
                if depth == 0 {
                    consume(ctx);
                    break;
                }
            }
            consume(ctx);
        }
        
        node.node_type = str("Case");
        node.data.case_node.value = str("");
        node.data.case_node.is_default = true;
        return node;
    }
    
    // For now, skip unknown tokens
    consume(ctx);
    return node;
}

test {
    initialize_all();
    
    println "\nTest 1: parse_type with simple type";
    mut tokens1: list(Token) = lex(str("i32"));
    mut ctx1: ParserContext;
    ctx1.tokens = addr_of(tokens1);
    ctx1.pos = 0;
    mut type1: string = parse_type(addr_of(ctx1));
    assert equals_c(type1, "i32"), "Expected i32.";

    println "\nTest 2: skip_whitespace";
    mut tokens2: list(Token) = lex(str("   \n  \t  i32"));
    mut ctx2: ParserContext;
    ctx2.tokens = addr_of(tokens2);
    ctx2.pos = 0;
    mut pos_before: i32 = ctx2.pos;
    skip_whitespace(addr_of(ctx2));
    assert ctx2.pos > pos_before, "Expected position to advance after skipping whitespace";

    println "\nTest 3: peek and consume";
    mut tokens3: list(Token) = lex(str("identifier"));
    mut ctx3: ParserContext;
    ctx3.tokens = addr_of(tokens3);
    ctx3.pos = 0;
    mut peeked: Token = peek(addr_of(ctx3));
    mut pos_after_peek: i32 = ctx3.pos;
    mut consumed: Token = consume(addr_of(ctx3));
    mut pos_after_consume: i32 = ctx3.pos;
    assert pos_after_peek == 0 and pos_after_consume == 1, "Expected position to advance after consume";

    println "\nTest 4: expect";
    mut tokens4: list(Token) = lex(str("def function_name"));
    mut ctx4: ParserContext;
    ctx4.tokens = addr_of(tokens4);
    ctx4.pos = 0;
    assert expect(addr_of(ctx4), TokenType.DEF), "Expected to find 'def' token";

    println "\nTest 5: parse_type with ref type";
    mut tokens5: list(Token) = lex(str("ref i32"));
    mut ctx5: ParserContext;
    ctx5.tokens = addr_of(tokens5);
    ctx5.pos = 0;
    mut type5: string = parse_type(addr_of(ctx5));
    assert str_len(type5) > 0, "Expected non-empty type string for 'ref i32'";
    assert str_contains_c(type5, "i32"), "Expected type to contain 'i32'";

    println "\nTest 6: parse_type with list type";
    mut tokens6: list(Token) = lex(str("list(Token)"));
    mut ctx6: ParserContext;
    ctx6.tokens = addr_of(tokens6);
    ctx6.pos = 0;
    mut type6: string = parse_type(addr_of(ctx6));
    assert str_len(type6) > 0, "Expected non-empty type for list(Token)";
    assert str_contains_c(type6, "Token"), "Expected type to contain 'Token'";

    println "\nTest 7: parse simple function with parse_function";
    mut tokens7: list(Token) = lex(str("foo(): i32 { return 42; }"));
    mut ctx7: ParserContext;
    ctx7.tokens = addr_of(tokens7);
    ctx7.pos = 0;
    mut func7: ASTNode = parse_function(addr_of(ctx7));
    assert equals_c(func7.node_type, "Function"), "Expected Function node type";

    println "\nTest 8: parse function with parameters";
    mut tokens8: list(Token) = lex(str("add(a: i32): i32 { return a; }"));
    mut ctx8: ParserContext;
    ctx8.tokens = addr_of(tokens8);
    ctx8.pos = 0;
    mut func8: ASTNode = parse_function(addr_of(ctx8));
    assert equals_c(func8.node_type, "Function"), "Expected Function node for function with params";

    println "\nTest 9: parse full program with def main";
    mut tokens9: list(Token) = lex(str("def main() { }"));
    mut empty_module: string = str("");
    mut ast9: ASTNode = parse(addr_of(tokens9), false, false, empty_module);
    assert equals_c(ast9.node_type, "Program"), "Expected Program AST node";

    println "\nTest 10: parse program with model definition";
    mut tokens10: list(Token) = lex(str("model Point { x: i32 } def main() { }"));
    mut ast10: ASTNode = parse(addr_of(tokens10), false, false, str(""));
    assert equals_c(ast10.node_type, "Program"), "Expected Program node with model";

    println "\nTest 11: parse program with enum definition";
    mut tokens11: list(Token) = lex(str("enum Color { Red } def main() { }"));
    mut ast11: ASTNode = parse(addr_of(tokens11), false, false, str(""));
    assert equals_c(ast11.node_type, "Program"), "Expected Program node with enum";

    println "\nTest 12: parse program with use statement";
    mut tokens12: list(Token) = lex(str("use std.io; def main() { }"));
    mut ast12: ASTNode = parse(addr_of(tokens12), false, false, str(""));
    assert equals_c(ast12.node_type, "Program"), "Expected Program node with use statement";

    println "\nTest 13: parse program with global val";
    mut tokens13: list(Token) = lex(str("val CONSTANT: i32 = 42; def main() { }"));
    mut ast13: ASTNode = parse(addr_of(tokens13), false, false, str(""));
    assert equals_c(ast13.node_type, "Program"), "Expected Program node with global val";

    println "\nTest 14: parse program with mut val";
    mut tokens14: list(Token) = lex(str("mut val counter: i32 = 0; def main() { }"));
    mut ast14: ASTNode = parse(addr_of(tokens14), false, false, str(""));
    assert equals_c(ast14.node_type, "Program"), "Expected Program node with mut val";

    println "\nTest 15: parse program with pub function";
    mut tokens15: list(Token) = lex(str("pub def helper() { } def main() { }"));
    mut ast15: ASTNode = parse(addr_of(tokens15), false, false, str(""));
    assert equals_c(ast15.node_type, "Program"), "Expected Program node with pub function";

    println "\nTest 16: parse empty test block";
    mut tokens16: list(Token) = lex(str("test { }"));
    mut ast16: ASTNode = parse(addr_of(tokens16), false, false, str(""));
    assert equals_c(ast16.node_type, "Program"), "Expected Program node with test block";

    println "\nTest 17: parse_type with pointer syntax";
    mut tokens17: list(Token) = lex(str("i32*"));
    mut ctx17: ParserContext;
    ctx17.tokens = addr_of(tokens17);
    ctx17.pos = 0;
    mut type17: string = parse_type(addr_of(ctx17));
    assert str_len(type17) > 0, "Expected non-empty type for i32*";
    assert str_contains_c(type17, "i32"), "Expected type to contain 'i32'";

    println "\nTest 18: parse multiple functions";
    mut tokens18: list(Token) = lex(str("def foo() { } def bar() { } def main() { }"));
    mut ast18: ASTNode = parse(addr_of(tokens18), false, false, str(""));
    assert equals_c(ast18.node_type, "Program"), "Expected Program node with multiple functions";

    println "\nTest 19: parse_statement_helper with break";
    mut tokens19: list(Token) = lex(str("break;"));
    mut ctx19: ParserContext;
    ctx19.tokens = addr_of(tokens19);
    ctx19.pos = 0;
    ctx19.is_axec = false;
    ctx19.check_entry_point = false;
    ctx19.current_module = str("");
    mut stmt19: ASTNode = parse_statement_helper(addr_of(ctx19));
    assert equals_c(stmt19.node_type, "Break"), "Expected Break node";

    println "\nTest 20: parse_statement_helper with return";
    mut tokens20: list(Token) = lex(str("return 42;"));
    mut ctx20: ParserContext;
    ctx20.tokens = addr_of(tokens20);
    ctx20.pos = 0;
    ctx20.is_axec = false;
    mut stmt20: ASTNode = parse_statement_helper(addr_of(ctx20));
    assert equals_c(stmt20.node_type, "Return"), "Expected Return node";
    assert str_contains_c(stmt20.data.return_node.expression, "42"), "Expected return expression to contain '42'";

    println "\nTest 21: parse_statement_helper with assert";
    mut tokens21: list(Token) = lex(str("assert x > 0, \"x must be positive\";"));
    mut ctx21: ParserContext;
    ctx21.tokens = addr_of(tokens21);
    ctx21.pos = 0;
    ctx21.is_axec = false;
    mut stmt21: ASTNode = parse_statement_helper(addr_of(ctx21));
    assert equals_c(stmt21.node_type, "Assert"), "Expected Assert node";
    assert str_len(stmt21.data.assert_node.condition) > 0, "Expected assert condition";
    assert str_len(stmt21.data.assert_node.message) > 0, "Expected assert message";

    println "\nTest 22: parse_statement_helper with unsafe block";
    mut tokens22: list(Token) = lex(str("unsafe { }"));
    mut ctx22: ParserContext;
    ctx22.tokens = addr_of(tokens22);
    ctx22.pos = 0;
    ctx22.is_axec = false;
    mut stmt22: ASTNode = parse_statement_helper(addr_of(ctx22));
    assert equals_c(stmt22.node_type, "Unsafe"), "Expected Unsafe node";

    println "\nTest 23: parse_statement_helper with if-elif-else";
    mut tokens23: list(Token) = lex(str("if x > 0 { println x; } elif x < 0 { println x; } else { println x; }"));
    mut ctx23: ParserContext;
    ctx23.tokens = addr_of(tokens23);
    ctx23.pos = 0;
    ctx23.is_axec = false;
    mut stmt23: ASTNode = parse_statement_helper(addr_of(ctx23));
    assert equals_c(stmt23.node_type, "If"), "Expected If node with elif and else";

    println "\nTest 24: parse_statement_helper with use statement";
    mut tokens24: list(Token) = lex(str("use std.io;"));
    mut ctx24: ParserContext;
    ctx24.tokens = addr_of(tokens24);
    ctx24.pos = 0;
    ctx24.is_axec = false;
    mut stmt24: ASTNode = parse_statement_helper(addr_of(ctx24));
    assert equals_c(stmt24.node_type, "Use"), "Expected Use node";
    assert stmt24.data.use_node.import_all == true, "Expected import_all to be true";

    println "\nTest 25: parse_statement_helper with use selective imports";
    mut tokens25: list(Token) = lex(str("use std.maps (StringIntMap, StringStringMap);"));
    mut ctx25: ParserContext;
    ctx25.tokens = addr_of(tokens25);
    ctx25.pos = 0;
    ctx25.is_axec = false;
    mut stmt25: ASTNode = parse_statement_helper(addr_of(ctx25));
    assert equals_c(stmt25.node_type, "Use"), "Expected Use node with selective imports";
    assert stmt25.data.use_node.import_all == false, "Expected import_all to be false";

    println "\nTest 26: parse_statement_helper with case";
    mut tokens26: list(Token) = lex(str("case 1 { println \"one\"; }"));
    mut ctx26: ParserContext;
    ctx26.tokens = addr_of(tokens26);
    ctx26.pos = 0;
    ctx26.is_axec = false;
    mut stmt26: ASTNode = parse_statement_helper(addr_of(ctx26));
    assert equals_c(stmt26.node_type, "Case"), "Expected Case node";
    assert stmt26.data.case_node.is_default == false, "Expected non-default case";

    println "\nTest 27: parse_statement_helper with default";
    mut tokens27: list(Token) = lex(str("default { println \"other\"; }"));
    mut ctx27: ParserContext;
    ctx27.tokens = addr_of(tokens27);
    ctx27.pos = 0;
    ctx27.is_axec = false;
    mut stmt27: ASTNode = parse_statement_helper(addr_of(ctx27));
    assert equals_c(stmt27.node_type, "Case"), "Expected Case node for default";
    assert stmt27.data.case_node.is_default == true, "Expected default case";

    println "\nTest 28: parse_statement_helper with member access assignment";
    mut tokens28: list(Token) = lex(str("obj.field = 42;"));
    mut ctx28: ParserContext;
    ctx28.tokens = addr_of(tokens28);
    ctx28.pos = 0;
    ctx28.is_axec = false;
    mut stmt28: ASTNode = parse_statement_helper(addr_of(ctx28));
    assert equals_c(stmt28.node_type, "MemberAccess"), "Expected MemberAccess node";
    assert equals_c(stmt28.data.member_access.object_name, "obj"), "Expected object name 'obj'";
    assert equals_c(stmt28.data.member_access.member_name, "field"), "Expected member name 'field'";
    assert str_contains_c(stmt28.data.member_access.value, "42"), "Expected value to contain '42'";

    println "\nTest 29: parse_statement_helper with member access read";
    mut tokens29: list(Token) = lex(str("obj.field;"));
    mut ctx29: ParserContext;
    ctx29.tokens = addr_of(tokens29);
    ctx29.pos = 0;
    ctx29.is_axec = false;
    mut stmt29: ASTNode = parse_statement_helper(addr_of(ctx29));
    assert equals_c(stmt29.node_type, "MemberAccess"), "Expected MemberAccess node";
    assert equals_c(stmt29.data.member_access.object_name, "obj"), "Expected object name 'obj'";
    assert equals_c(stmt29.data.member_access.member_name, "field"), "Expected member name 'field'";
    assert equals_c(stmt29.data.member_access.value, ""), "Expected empty value for read access";

    println "\nTest 30: parse_statement_helper with array access";
    mut tokens30: list(Token) = lex(str("arr[5];"));
    mut ctx30: ParserContext;
    ctx30.tokens = addr_of(tokens30);
    ctx30.pos = 0;
    ctx30.is_axec = false;
    mut stmt30: ASTNode = parse_statement_helper(addr_of(ctx30));
    assert equals_c(stmt30.node_type, "ArrayAccess"), "Expected ArrayAccess node";
    assert equals_c(stmt30.data.array_access.array_name, "arr"), "Expected array name 'arr'";
    assert str_contains_c(stmt30.data.array_access.index, "5"), "Expected index to contain '5'";

    println "\nTest 31: parse_statement_helper with array assignment";
    mut tokens31: list(Token) = lex(str("arr[i] = 42;"));
    mut ctx31: ParserContext;
    ctx31.tokens = addr_of(tokens31);
    ctx31.pos = 0;
    ctx31.is_axec = false;
    mut stmt31: ASTNode = parse_statement_helper(addr_of(ctx31));
    assert equals_c(stmt31.node_type, "ArrayAssign"), "Expected ArrayAssign node";
    assert equals_c(stmt31.data.array_assign.array_name, "arr"), "Expected array name 'arr'";
    assert str_contains_c(stmt31.data.array_assign.index, "i"), "Expected index to contain 'i'";
    assert str_contains_c(stmt31.data.array_assign.value, "42"), "Expected value to contain '42'";

    println "\nTest 32: parse_statement_helper with 2D array access";
    mut tokens32: list(Token) = lex(str("matrix[i][j];"));
    mut ctx32: ParserContext;
    ctx32.tokens = addr_of(tokens32);
    ctx32.pos = 0;
    ctx32.is_axec = false;
    mut stmt32: ASTNode = parse_statement_helper(addr_of(ctx32));
    assert equals_c(stmt32.node_type, "ArrayAccess"), "Expected ArrayAccess node for 2D array";
    assert equals_c(stmt32.data.array_access.array_name, "matrix"), "Expected array name 'matrix'";
    assert str_contains_c(stmt32.data.array_access.index, "i"), "Expected first index to contain 'i'";
    assert str_contains_c(stmt32.data.array_access.index2, "j"), "Expected second index to contain 'j'";

    println "\nTest 33: parse_statement_helper with increment";
    mut tokens33: list(Token) = lex(str("x++;"));
    mut ctx33: ParserContext;
    ctx33.tokens = addr_of(tokens33);
    ctx33.pos = 0;
    ctx33.is_axec = false;
    mut stmt33: ASTNode = parse_statement_helper(addr_of(ctx33));
    assert equals_c(stmt33.node_type, "IncDec"), "Expected IncDec node";
    assert equals_c(stmt33.data.inc_dec.variable, "x"), "Expected variable name 'x'";
    assert stmt33.data.inc_dec.is_increment == true, "Expected is_increment to be true";

    println "\nTest 34: parse_statement_helper with decrement";
    mut tokens34: list(Token) = lex(str("x--;"));
    mut ctx34: ParserContext;
    ctx34.tokens = addr_of(tokens34);
    ctx34.pos = 0;
    ctx34.is_axec = false;
    mut stmt34: ASTNode = parse_statement_helper(addr_of(ctx34));
    assert equals_c(stmt34.node_type, "IncDec"), "Expected IncDec node";
    assert equals_c(stmt34.data.inc_dec.variable, "x"), "Expected variable name 'x'";
    assert stmt34.data.inc_dec.is_increment == false, "Expected is_increment to be false";

    println "\nTest 35: parse_statement_helper with member increment";
    mut tokens35: list(Token) = lex(str("obj.count++;"));
    mut ctx35: ParserContext;
    ctx35.tokens = addr_of(tokens35);
    ctx35.pos = 0;
    ctx35.is_axec = false;
    mut stmt35: ASTNode = parse_statement_helper(addr_of(ctx35));
    assert equals_c(stmt35.node_type, "MemberIncDec"), "Expected MemberIncDec node";
    assert equals_c(stmt35.data.member_inc_dec.object_name, "obj"), "Expected object name 'obj'";
    assert equals_c(stmt35.data.member_inc_dec.member_name, "count"), "Expected member name 'count'";
    assert stmt35.data.member_inc_dec.is_increment == true, "Expected is_increment to be true";

    println "\nTest 36: parse_statement_helper with member decrement";
    mut tokens36: list(Token) = lex(str("obj.count--;"));
    mut ctx36: ParserContext;
    ctx36.tokens = addr_of(tokens36);
    ctx36.pos = 0;
    ctx36.is_axec = false;
    mut stmt36: ASTNode = parse_statement_helper(addr_of(ctx36));
    assert equals_c(stmt36.node_type, "MemberIncDec"), "Expected MemberIncDec node";
    assert equals_c(stmt36.data.member_inc_dec.object_name, "obj"), "Expected object name 'obj'";
    assert equals_c(stmt36.data.member_inc_dec.member_name, "count"), "Expected member name 'count'";
    assert stmt36.data.member_inc_dec.is_increment == false, "Expected is_increment to be false";

    println "\nTest 37: A complete program parse";
    mut tokens37: list(Token) = lex(str(`use std.io;
        
        model Point {
            x: i32;
            y: i32;
        }
        
        enum Color {
            Red,
            Green,
            Blue
        }
        
        pub def main() {
            val p: Point = Point { x: 10, y: 20 };
            println p.x;
        }
    `));
    
    mut ctx37: ParserContext;

    ctx37.tokens = addr_of(tokens37);
    ctx37.pos = 0;
    ctx37.is_axec = false;

    mut stmt37: ASTNode = parse_statement_helper(addr_of(ctx37));
    
    assert equals_c(stmt37.node_type, "Use"), "Expected Use node as first statement in program";
    assert equals_c(stmt37.data.use_node.module_name, "std.io"), "Expected module name 'std.io'";
}
