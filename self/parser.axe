// Author: Navid Momtahen (C) 2025
// License: GPL-3.0
// 
// Handles the parsing process - converts tokens into an AST

use lexer (
    Token, 
    TokenType, lex
);

use structs (
    ASTNode
);

use std.string;
use std.io;
use std.maps;
use std.arena;

mut g_type_aliases: StringHashMapString;
mut g_imported_modules: StringHashMapBool;
mut g_list_of_types: StringHashMapString;
// mut g_macros: map(string, MacroDef);

def initialize_all() {
    mut arena: Arena = Arena.create(1024 * 1024);
    g_type_aliases = deref(StringHashMapString.create(ref_of(arena), 128));
    g_imported_modules = deref(StringHashMapBool.create(ref_of(arena), 128));
    g_list_of_types = deref(StringHashMapString.create(ref_of(arena), 128));
}


/// Parser context - holds state during parsing
model ParserContext {
    tokens: list(Token);
    pos: i32;
    is_axec: bool;
    check_entry_point: bool;
    current_module: string;
    current_scope: Scope;
}

/// Scope tracking for variable declarations
model Scope {
    variables: StringHashMapString;
    parent: ref Scope;
}

/// Parse the tokens into an AST
pub def parse(tokens: list(Token), is_axec: bool, check_entry_point: bool, current_module: string): ASTNode {
    mut ctx: ParserContext;
    ctx.tokens = tokens;
    ctx.pos = 0;
    ctx.is_axec = is_axec;
    ctx.check_entry_point = check_entry_point;
    ctx.current_module = current_module;
    
    mut ast: ASTNode;
    ast.node_type = str("Program");
    
    StringHashMapString.clear(addr_of(g_type_aliases));
    StringHashMapBool.clear(addr_of(g_imported_modules));
    StringHashMapString.clear(addr_of(g_list_of_types));
    
    if str_len(current_module) > 0 {
        // g_imported_modules[current_module] = true
        println "Auto-imported current module: ";
        println current_module;
    }
    
    loop {
        if ctx.pos >= len(tokens) {
            break;
        }
        skip_whitespace(addr_of(ctx));        
        if ctx.pos >= len(tokens) {
            break;
        }
        parse_top_level(addr_of(ctx), addr_of(ast));
    }
    
    return ast;
}

/// Parse a top-level construct (use, def, model, enum, val, mut val, etc.)
def parse_top_level(ctx: ref ParserContext, ast: ref ASTNode) {
    if ctx.pos >= len(ctx.tokens) {
        return;
    }
    
    val token_type = ctx.tokens.data[ctx.pos].token_type;
    
    // Handle USE statements
    if token_type == TokenType.USE {
        ctx.pos++;
        skip_whitespace(ctx);
        
        // TODO: Parse module path. 
        // For now, just skip until semicolon
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            if ctx.tokens.data[ctx.pos].token_type == TokenType.SEMICOLON {
                ctx.pos++;
                break;
            }
            ctx.pos++;
        }
        return;
    }
    
    // Handle DEF (function definitions)
    if token_type == TokenType.DEF {
        ctx.pos++;
        skip_whitespace(ctx);
        
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
            ctx.pos++;
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LPAREN {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LPAREN {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RPAREN {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.COLON {
            ctx.pos++;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    break;
                }
                ctx.pos++;
            }
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    // Handle MODEL definitions
    if token_type == TokenType.MODEL {
        ctx.pos++;
        skip_whitespace(ctx);
        
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
            ctx.pos++;
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    // Handle ENUM definitions
    if token_type == TokenType.ENUM {
        ctx.pos++;  // Skip 'enum'
        skip_whitespace(ctx);
        
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
            ctx.pos++;
        }
        
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    if token_type == TokenType.MUT {
        ctx.pos++;
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.VAL {
            ctx.pos++;  // Skip 'val'
        }
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            if ctx.tokens.data[ctx.pos].token_type == TokenType.SEMICOLON {
                ctx.pos++;
                break;
            }
            ctx.pos++;
        }
        return;
    }
    
    // Handle VAL (immutable global variables)
    if token_type == TokenType.VAL {
        ctx.pos++;  // Skip 'val'
        // Skip until semicolon
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            if ctx.tokens.data[ctx.pos].token_type == TokenType.SEMICOLON {
                ctx.pos++;
                break;
            }
            ctx.pos++;
        }
        return;
    }
    
    // Handle TEST blocks
    if token_type == TokenType.TEST {
        ctx.pos++;  // Skip 'test'
        skip_whitespace(ctx);
        
        // Skip test body
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    // Handle PUB modifier
    if token_type == TokenType.PUB {
        ctx.pos++;  // Skip 'pub'
        skip_whitespace(ctx);
        // Recursively handle the next item
        parse_top_level(ctx, ast);
        return;
    }
    
    // Handle MACRO definitions
    if token_type == TokenType.MACRO {
        ctx.pos++;  // Skip 'macro'
        skip_whitespace(ctx);
        
        // Skip macro name
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.IDENTIFIER {
            ctx.pos++;
        }
        
        // Skip parameters
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LPAREN {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LPAREN {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RPAREN {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        
        // Skip macro body
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    // Handle OPAQUE type declarations
    if token_type == TokenType.OPAQUE {
        ctx.pos++;  // Skip 'opaque'
        loop {
            if ctx.pos >= len(ctx.tokens) {
                break;
            }
            if ctx.tokens.data[ctx.pos].token_type == TokenType.SEMICOLON {
                ctx.pos++;
                break;
            }
            ctx.pos++;
        }
        return;
    }
    
    // Handle PLATFORM blocks
    if token_type == TokenType.PLATFORM {
        ctx.pos++;  // Skip 'platform'
        skip_whitespace(ctx);
        
        // Skip platform name (windows/posix)
        if ctx.pos < len(ctx.tokens) {
            ctx.pos++;
        }
        
        // Skip platform body
        skip_whitespace(ctx);
        if ctx.pos < len(ctx.tokens) and ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
            ctx.pos++;
            mut depth: i32 = 1;
            loop {
                if ctx.pos >= len(ctx.tokens) {
                    break;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.LBRACE {
                    depth = depth + 1;
                }
                if ctx.tokens.data[ctx.pos].token_type == TokenType.RBRACE {
                    depth = depth - 1;
                    if depth == 0 {
                        ctx.pos++;
                        break;
                    }
                }
                ctx.pos++;
            }
        }
        return;
    }
    
    // Unknown token type - skip it
    ctx.pos++;
}

/// Skip the whitespace and newline tokens
def skip_whitespace(ctx: ref ParserContext) {
    loop {
        if ctx.pos >= len(ctx.tokens) {
            break;
        }
        
        val token_type = ctx.tokens.data[ctx.pos].token_type;
        
        if token_type == TokenType.WHITESPACE or token_type == TokenType.NEWLINE {
            ctx.pos++;
        } else {
            break;
        }
    }
}

/// Peek at current token without advancing
def peek(ctx: ref ParserContext): Token {
    if ctx.pos < len(ctx.tokens) {
        return ctx.tokens.data[ctx.pos];
    }
    
    mut empty: Token;
    empty.token_type = TokenType.IDENTIFIER;
    empty.value = str("");
    empty.line = 0;
    empty.column = 0;
    return empty;
}

// // Consume current token and advance
// def consume(ctx: ref ParserContext): Token {
//     val token = peek(ctx);
//     ctx.pos = ctx.pos + 1;
//     return token;
// }

// // Check if current token matches expected type
// def expect(ctx: ref ParserContext, expected_type: i32): bool {
//     skip_whitespace(ctx);
//     val token = peek(ctx);
//     return token.token_type == expected_type;
// }

// // Parse a type specification (e.g., "i32", "ref string", "list(Token)")
// def parse_type(ctx: ref ParserContext): string {
//     skip_whitespace(ctx);
    
//     if ctx.pos >= len(ctx.tokens) {
//         println "ERROR: Expected type but reached end of tokens";
//         return str("");
//     }
    
//     mut ref_prefix: string = str("");
    
//     loop {
//         val token = peek(ctx);
//         if token.token_type == TokenType.REF {
//             ref_prefix = concat(ref_prefix, "ref ");
//             consume(ctx);
//             skip_whitespace(ctx);
//         } else {
//             break;
//         }
//     }
    
//     mut type_name: string = "";
//     val token = peek(ctx);
    
//     // Handle 'model' keyword as type for anonymous models
//     if token.token_type == TokenType.MODEL {
//         consume(ctx);
//         return concat(ref_prefix, "model");
//     }
    
//     if token.token_type == TokenType.IDENTIFIER {
//         type_name = token.value;
//         consume(ctx);
        
//         // Handle list(ElementType) syntax
//         if equals_c(type_name, "list") {
//             skip_whitespace(ctx);
            
//             if !expect(ctx, TokenType.LPAREN) {
//                 println "ERROR: Expected '(' after 'list'";
//                 return "";
//             }
//             consume(ctx);
            
//             skip_whitespace(ctx);
//             val elem_token = consume(ctx);
//             val element_type = elem_token.value;
            
//             skip_whitespace(ctx);
//             if !expect(ctx, TokenType.RPAREN) {
//                 println "ERROR: Expected ')' after list element type";
//                 return "";
//             }
//             consume(ctx);
//             type_name = concat(element_type, "[999]");
            
//             println "DEBUG: Parsed list(";
//             println element_type;
//             println ") -> ";
//             println type_name;
//         }

//         // Handle array brackets [size]
//         loop {
//             if expect(ctx, TokenType.LBRACKET) {
//                 consume(ctx);
//                 type_name = concat(type_name, "[");
                
//                 loop {
//                     val tok = peek(ctx);
//                     if tok.token_type == TokenType.RBRACKET {
//                         break;
//                     }
//                     type_name = concat(type_name, tok.value);
//                     consume(ctx);
//                 }
                
//                 if expect(ctx, TokenType.RBRACKET) {
//                     consume(ctx);
//                     type_name = concat(type_name, "]");
//                 }
//             } else {
//                 break
//             }
//         }
        
//         // Handle pointer syntax *
//         loop {
//             val tok = peek(ctx);
//             if tok.token_type == TokenType.OPERATOR && equals_c(tok.value, "*") {
//                 consume(ctx)
//                 type_name = concat(type_name, "*");
//             } else {
//                 break;
//             }
//         }
//     } else {
//         println "ERROR: Invalid type specification";
//         return "";
//     }
    
//     // TODO: Check type aliases
//     // if type_name in g_type_aliases {
//     //     type_name = g_type_aliases[type_name]
//     // }
    
//     return concat(ref_prefix, type_name);
// }

// // Parse ref depth (e.g., "ref ref int" returns 2)
// def parse_ref_depth(ctx: ref ParserContext): i32 {
//     mut depth: i32 = 0;
    
//     loop {
//         skip_whitespace(ctx);
        
//         if ctx.pos >= len(ctx.tokens) {
//             break;
//         }
        
//         val token = peek(ctx);
//         if token.token_type == TokenType.REF {
//             depth++;
//             consume(ctx);
//         } else {
//             break;
//         }
//     }
    
//     return depth;
// }

// // TODO:                Implement remaining parser functions
// // - parse_top_level:   Parse use, model, enum, function, etc.
// // - parse_function:    Parse function definitions
// // - parse_model:       Parse model definitions
// // - parse_enum:        Parse enum definitions
// // - parse_statement:   Parse statements in function bodies
// // - parse_expression:  Parse expressions
// // - parse_block:       Parse { ... } blocks

// def main() {
//     println "Parser module loaded";
//     println "TODO: Implement remaining parser functions";
// }

test {

}
